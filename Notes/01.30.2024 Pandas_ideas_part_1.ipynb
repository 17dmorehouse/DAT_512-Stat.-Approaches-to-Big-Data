{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68b6bd9",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas is a python package for importing and working with tabular data,  such as spreadsheet tables\n",
    "\n",
    "It provides for a dataframe style interface,  very similar to data frames in R\n",
    "\n",
    "Pandas is using NumPy matrices \"underneath\" the Pandas structures,  and it is easy to \"extract\" NumPy matrices from a Pandas \n",
    "dataframe.   Many functions in sklearn and other packages will accept either Pandas data frames or NumPy matrices as inputs.\n",
    "\n",
    "Pandas allows for different types of data per column, as opposed by the requirement in NumPy that the matrices be homogeneous.\n",
    "\n",
    "Pandas has a massive number of built in functions,  that allow for vectorized operations on the DataFrame,  plus a bunch of visualization tools built into it.\n",
    "\n",
    "Pandas does have some quirks in how you handle accessing and slicing the data, it doesn't use the standard square bracket approach   df[1,2] does not work,  watch for that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ef19",
   "metadata": {},
   "source": [
    "# Sources of this material\n",
    "\n",
    "Chapter 5 of \"Python for Data Analysis\"- Wes McKinney\n",
    "\n",
    "    https://learning.oreilly.com/library/view/python-for-data/9781491957653/ch05.html\n",
    "    \n",
    "The Pandas website is at\n",
    "\n",
    "    https://pandas.pydata.org/\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930cd72",
   "metadata": {},
   "source": [
    "# Panda Series\n",
    "\n",
    "1-D array like objects in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896dd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced7daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a series from a list\n",
    "\n",
    "#lists have indices and objects\n",
    "\n",
    "my_obj=pd.Series([4,7,-9,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccc37bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2   -9\n",
       "3    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f372e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  7, -9,  2], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_obj.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8c6f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the index to this obj\n",
    "\n",
    "my_obj.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2056ac3",
   "metadata": {},
   "source": [
    "Question- what is a RangeIndex??   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a1d3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can specify the index when creating the series\n",
    "\n",
    "my_series2=pd.Series([-1,2,3,11],index=['a','b','c','d'])\n",
    "\n",
    "# we can then select values with the index- note this as a difference from a numpy array\n",
    "\n",
    "my_series2['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af6fa3",
   "metadata": {},
   "source": [
    "A series is sort of like a fixed length dictionary,  it is easy to create a series from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b574d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio              2\n",
       "Pennsylvania     11\n",
       "Texas           311\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_dict={\"Ohio\":2,\"Pennsylvania\":11,\"Texas\":311}\n",
    "\n",
    "my_series3=pd.Series(s_dict)\n",
    "\n",
    "my_series3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832d696",
   "metadata": {},
   "source": [
    "Series automatically align the indexes when you do operations with them,  kind like a join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1eb54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New York          NaN\n",
       "Ohio             10.0\n",
       "Pennsylvania     20.0\n",
       "Texas           321.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s_dict2={\"Ohio\":8,\"Pennsylvania\":9,\"New York\":89,\"Texas\":10}\n",
    "\n",
    "my_series4=pd.Series(s_dict2)\n",
    "\n",
    "my_series3+my_series4\n",
    "\n",
    "#note the insertion of NaN when there is no matching entry,   output is also sorted by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd01fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New York         True\n",
       "Ohio            False\n",
       "Pennsylvania    False\n",
       "Texas           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detecting the null entry\n",
    "\n",
    "out_series=my_series3+my_series4\n",
    "\n",
    "out_series.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d521c1",
   "metadata": {},
   "source": [
    "The interesting feature of Pandas Series is that the can be date indexed,  so that the series is representing a time series\n",
    "in this form, there are a whole bunch of member functions for working with the data as a time series.\n",
    "\n",
    "See\n",
    "\n",
    "    https://pandas.pydata.org/docs/reference/series.html\n",
    "\n",
    "We'll see about coming back to time series analysis a bit later if I can locate a good discussion of how Pandas series are used\n",
    "in this approach.  They seem to be more commonly found as a component of pandas dataframes.\n",
    "\n",
    "\n",
    "    https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41819e24",
   "metadata": {},
   "source": [
    "# DataFrames in Pandas\n",
    "\n",
    "Pandas has dataframes,   each column of a data frame is a Pandas series,  these are the two basic storage forms in Pandas\n",
    "\n",
    "We can move data into Pandas data frames in a number of ways\n",
    "\n",
    "-manual entry\n",
    "\n",
    "-importing CSV files\n",
    "\n",
    "-pulling data from databases or from website APIs\n",
    "\n",
    "The R data type \"Factor\" doesn't exist in Pandas (sadly)- you wind up using either strings or integers as factor-like \n",
    "variables-  you wind up using what is called either integer coding of categories, or \"one-hot\" encoding,  more on that later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5abac3",
   "metadata": {},
   "source": [
    "# Manually entering data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6924d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting variables into a data frame\n",
    "a=np.array([1,2,3,4])\n",
    "b=[\"Hey\",\"Hey\",\"My\",\"My\"]\n",
    "c=(1.2, 2.1, 1.3, -2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ce97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one or more cells to figure out what type of objects a, b and c are,  also what type of data is in each-  show this \n",
    "# work in this cell\n",
    "\n",
    "# when looking at examples,  always, always be aware of what data types are in use\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96469f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hey</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>My</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>My</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x    y    z\n",
       "0  1  Hey  1.2\n",
       "1  2  Hey  2.1\n",
       "2  3   My  1.3\n",
       "3  4   My -2.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually entering data into a dataframe\n",
    "# insert into a data frame\n",
    "# note that the data here is forced into the form of a dictionary, with the variable names in quotes\n",
    "\n",
    "stuff_df=pd.DataFrame({'x':a,'y':b,'z':c})\n",
    "\n",
    "stuff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fef98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev46\\AppData\\Local\\Temp\\ipykernel_4740\\1590861413.py:16: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  redwine_df=pd.read_csv(infile, sep=\"\\;|\\,\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hdavi\\\\Dropbox\\\\Data_Analytics\\\\DAT511_Data_Cleaning\\\\Lectures_Fall_2018\\\\Example_data\\\\UCI_wine_data\\\\winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m      4\u001b[0m infile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mhdavi\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDropbox\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData_Analytics\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDAT511_Data_Cleaning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLectures_Fall_2018\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mExample_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUCI_wine_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwinequality-red.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# notice here that a regex string specifier is used in the pd.read_csv() funtion here \"\\;|\\,\" to indicate that the separator \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# (or delimiter) being used is \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# \";\" or \",\",   the escape code \\ is uses so that : and , are intrepeted as charactoers\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#  there is also pd.read_table available,  which reads a range of formats\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m redwine_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(infile, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m;|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# we have an available member function head to let us look at the data\u001b[39;00m\n\u001b[0;32m     21\u001b[0m redwine_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hdavi\\\\Dropbox\\\\Data_Analytics\\\\DAT511_Data_Cleaning\\\\Lectures_Fall_2018\\\\Example_data\\\\UCI_wine_data\\\\winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "# reading a csv file\n",
    "#we will look at the standard red-wine data set\n",
    "\n",
    "infile=\"C:\\\\Users\\\\hdavi\\\\Dropbox\\\\Data_Analytics\\\\DAT511_Data_Cleaning\\\\Lectures_Fall_2018\\\\Example_data\\\\UCI_wine_data\\\\winequality-red.csv\"\n",
    "\n",
    "# notice here that a regex string specifier is used in the pd.read_csv() funtion here \"\\;|\\,\" to indicate that the separator \n",
    "# (or delimiter) being used is \n",
    "# \";\" or \",\",   the escape code \\ is uses so that : and , are intrepeted as charactoers\n",
    "\n",
    "# The red wine set used here is labeled as a csv is not really comma delimited (sigh),   it is ; delimited\n",
    "\n",
    "# sep=\"\\;\" would have worked fine here,   I used the regex expression to show how to allow for two different delimiters.\n",
    "\n",
    "#  there is also pd.read_table available,  which reads a range of formats\n",
    "\n",
    "redwine_df=pd.read_csv(infile, sep=\"\\;|\\,\")\n",
    "\n",
    "\n",
    "# we have an available member function head to let us look at the data\n",
    "\n",
    "redwine_df.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API fetch\n",
    "\n",
    "#this is a data frame download from the Open Data Buffalo repository at\n",
    "#https://data.buffalony.gov/\n",
    "\n",
    "# in this case, thei s a copy of the City of Buffalo Public Art Inventory\n",
    "# note this just makes use of pd.read_csv again with the url from the data set,  which I found on Open Data Buffalo\n",
    "\n",
    "url=\"https://data.buffalony.gov/resource/6xz2-syui.csv\"\n",
    "    \n",
    "df_art=pd.read_csv(url)\n",
    "\n",
    "#make sure the data frome has no white space in the column names- this causes odd problems later\n",
    "\n",
    "df_art.columns = df_art.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a250a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_art.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df843ee",
   "metadata": {},
   "source": [
    "# Other input functions\n",
    "\n",
    "There are a large number of pandas read functions,  see\n",
    "\n",
    "    https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html?highlight=read_csv\n",
    "\n",
    "It can read excel files,  csv, pickled data, general \"tables\" from text files or url, off of the clipboard, json files, html files or sites, hdf, feather, parquet, sas, spss, sql tables, stata file etc\n",
    "\n",
    "It can write to most of these file formats as well.\n",
    "\n",
    "Writing to a csv is very simple,   df.to_csv() for example writes a dataframe to a csv,  with labels etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde7104",
   "metadata": {},
   "source": [
    "# basic information and plots\n",
    "\n",
    "Pandas has a lot of basic functions built in,  we would look at them using the redwine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21dc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the head function\n",
    "\n",
    "redwine_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae9a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic info\n",
    "# size, shape and ndim\n",
    "\n",
    "#size- number of elements in the array\n",
    "print(redwine_df.size)\n",
    "#shape,   rows by columns\n",
    "print(redwine_df.shape)\n",
    "#ndim  number of dimensions\n",
    "print(redwine_df.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc02c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "redwine_df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip any white space out of the column names\n",
    "# the pandas load function is prone to having trouble with leading or trailing whitespace\n",
    "\n",
    "\n",
    "redwine_df.columns = redwine_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In R, we had the summary function to give us a overview of the data frame values\n",
    "# in python the equivalent is the member function describe\n",
    "\n",
    "redwine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd61aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a lot of columns\n",
    "redwine_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5eb43b",
   "metadata": {},
   "source": [
    "We have some weird double quote thing going on here,  we should probably figure out how to clean that up,  use some sort of \n",
    "regex approach\n",
    "\n",
    "It turns out that pandas has a member function to change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d4411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can apply describe to only specific columns if desired\n",
    "redwine_df[['\"citric acid\"','\"chlorides\"']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have member functions for count, mean, median etc\n",
    "\n",
    "print(redwine_df[ '\"alcohol\"'].mean())\n",
    "print(redwine_df[ '\"alcohol\"'].median())\n",
    "print(redwine_df[ '\"alcohol\"'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93117ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find the location or index of the things like the min and max\n",
    "\n",
    "print(redwine_df['\"alcohol\"'].idxmax())\n",
    "print(redwine_df['\"alcohol\"'].idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply these to all columns\n",
    "\n",
    "redwine_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fc2ec",
   "metadata": {},
   "source": [
    "Pandas has some built-in plot functions,\n",
    "\n",
    "note the need here for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "redwine_df['\"citric acid\"'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ef096",
   "metadata": {},
   "source": [
    "# Question or goal to complete\n",
    "\n",
    "Go to open data buffalo,   look under \"data\" and filter down to show only datasets.\n",
    "\n",
    "Find an interesting looking data set,  find the URL for the dataset and load it into a pandas data frame,  using the URL if \n",
    "you can.\n",
    "\n",
    "Some of the URL links load the data in ways that are not compatible with the pd.read_csv function.  If that happens,  download\n",
    "the data as a CSV and load it that way\n",
    "\n",
    "Find out the following,  putting each of these in separate cell and adding comments to the notebooks\n",
    "\n",
    "-the size of the data \n",
    "-show the head\n",
    "-use describe() to get some basic statistics\n",
    "-show the column names\n",
    "- try to create a histogram of one column,  if you have continuous data in the dataframe\n",
    "\n",
    "\n",
    "If you have dates in the dataset,  convert that column to the pandas datatime object\n",
    "\n",
    "                  df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "\n",
    " pandas has member functions for working with dates as distinct type of variable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088466bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "313b794b",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "This allows you to apply the built in operations using a categorical grouping variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11462b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# there is a group by operation available\n",
    "# note that in the groupy operation, I had to give the full name of the column df_art['type']\n",
    "# which not what the pandas manual indicates\n",
    "\n",
    "df_art['title'].groupby(df_art['type']).count()              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f660ac",
   "metadata": {},
   "source": [
    "Creating a Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.pivot_table(df_art,values='category',index=['site','type'],columns='city',aggfunc=\"count\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc5402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_art.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c82fcb",
   "metadata": {},
   "source": [
    "# Question or goal\n",
    "\n",
    "Figure out how to create a Pivot table using the data you downloaded from Open Data Buffalo\n",
    "\n",
    "Look for categories, and use the count option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb2d81",
   "metadata": {},
   "source": [
    "# Melting a data frame\n",
    "\n",
    "Converts a \"wide format\" data frame into a \"long format\" data frame\n",
    "\n",
    "In a long format data frame,  we have 1 or more identifier columns,  here I used title as the identifier- think of this\n",
    "like a data base index.   Note, you can have a composite index of more than one column\n",
    "\n",
    "The other two columns are the name of the variable followed by the value\n",
    "\n",
    "So the \"melted form\" is always  index, variable, value\n",
    "\n",
    "Some types of operations are easily carried out on the melted or long form of a dataframe\n",
    "\n",
    "I've figured out some cool plotting tactics, but other than that I don't use this form much.  I should learn to do that \n",
    "more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ed2dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp=pd.melt(df_art,id_vars=['title'],value_vars=['category','type','photo_url_link','latitude','longitude'])\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e248a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340766b4",
   "metadata": {},
   "source": [
    "#  Question- Create a melt of your data set, with a couple of variables included\n",
    "\n",
    "What variable or variables will you need in your index.  Do you need a composite index?\n",
    "\n",
    "Bonus- how could you make use of this melted version of the data?   I've used melted data to produce some interesting plots, but it's tough to think of other uses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af35c03",
   "metadata": {},
   "source": [
    "# Slicing and accessing sections of a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b542ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example frame from a dictionary\n",
    "\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "t_frame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac654338",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1961586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing colums, two forms\n",
    "\n",
    "print(t_frame['state'])\n",
    "print(\"--------------------------\")\n",
    "\n",
    "print(t_frame.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is also a loc attribute that can pull rows\n",
    "\n",
    "t_frame.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_frame.loc[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0294e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add columns by assignment\n",
    "t_frame['debt'] =-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe1b42",
   "metadata": {},
   "source": [
    "Look at t_frame after the debt term was added,  what has happened?   Can you figure out how to set debt to a set of different\n",
    "random values (1 per state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ab8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a boolean column to t-frame identifying eastern states\n",
    "\n",
    "t_frame['eastern']= (t_frame.state==\"Ohio\")\n",
    "\n",
    "t_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the del method to remove a column\n",
    "\n",
    "del t_frame['eastern']\n",
    "\n",
    "t_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing- changeing the order of columns or rows\n",
    "\n",
    "a=pd.Series([4.5,7.2,-5.3,3.6], index=['d','b','a','c'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=a.reindex(['a','b','c','d'])\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering a data frame\n",
    "\n",
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'],columns=['Ohio', 'Texas', 'California'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = frame.reindex(['a', 'b', 'c', 'd'])\n",
    "\n",
    "# note the insertion of the blank row for b,  NaN means not a number\n",
    "\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1329f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering columns,  using the columns keyword\n",
    "\n",
    "states = ['Texas', 'Utah', 'California']\n",
    "\n",
    "frame.reindex(columns=states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0aa85",
   "metadata": {},
   "source": [
    "It's not obvious to me what the point of reindexing is,  I guess you could clean up the appearance of dataframes\n",
    "for output?  Any ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping elements\n",
    "\n",
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),index=['Ohio', 'Colorado', 'Utah', 'New York'],columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Ohio','Colorado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ae795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['two','four'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e42033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing with integers- works like standard numpy or python index- note the need to use iloc()\n",
    "\n",
    "data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af4450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loc uses the column and row names\n",
    "\n",
    "data.loc[[\"Colorado\",\"Utah\"],\"three\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46abbd",
   "metadata": {},
   "source": [
    "# Question/activity\n",
    "\n",
    "Show several slices of your data frame,   using column names and integer locations\n",
    "\n",
    "Explain what is happening in the slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ffb63",
   "metadata": {},
   "source": [
    "# Function Application and Mapping\n",
    "\n",
    "Mapping refers to applying functions across a data structure\n",
    "\n",
    "The numpy methods also work on Pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'),index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying a lambda function to the columns of an array\n",
    "# a lambda function is one defined in a single line\n",
    "\n",
    "f=lambda x: x.max()-x.min()\n",
    "\n",
    "# the default apply() is by column,   as per the R apply() function\n",
    "\n",
    "frame.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use apply() across rows instead of columns\n",
    "\n",
    "frame.apply(f,axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a250d5",
   "metadata": {},
   "source": [
    "Note that there are a number of member functions, which don't require the use of apply(),   frame.mean(), max, min, sum\n",
    "etc\n",
    "\n",
    "use dir(frame) to see what is availabe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d7e5f",
   "metadata": {},
   "source": [
    "There is a version of apply called applymap() that acts on each element in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysquare= lambda x: x**2\n",
    "\n",
    "frame.applymap(mysquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by index\n",
    "\n",
    "tseries = pd.Series(range(4), index=['d', 'a', 'b', 'c'])\n",
    "\n",
    "tseries.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tframe = pd.DataFrame(np.arange(8).reshape((2, 4)),index=['three', 'one'],columns=['d', 'a', 'b', 'c'])\n",
    "tframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by row\n",
    "tframe.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by column\n",
    "\n",
    "tframe.sort_index(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278eb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by values,  rather than by indices\n",
    "tframe.sort_values(by=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d17377",
   "metadata": {},
   "source": [
    "#Question\n",
    "\n",
    "produce a version of your data set from open data buffalo,  sorted by one of the columns\n",
    "\n",
    "Figure out how to create a reversed or backwards sorted version of the data frame as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
