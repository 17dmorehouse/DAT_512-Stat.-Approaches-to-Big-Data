{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":830053,"sourceType":"datasetVersion","datasetId":437114},{"sourceId":3036086,"sourceType":"datasetVersion","datasetId":1859421},{"sourceId":6518040,"sourceType":"datasetVersion","datasetId":3711894},{"sourceId":420,"sourceType":"datasetVersion","datasetId":19}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Spark Iris Intro\n\nRunning Spark in a Kaggle Notebook\n\na modified version of: \n\nhttps://www.kaggle.com/kkhandekar/apache-spark-beginner-tutorial","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-26T16:07:30.773700Z","iopub.execute_input":"2024-03-26T16:07:30.774088Z","iopub.status.idle":"2024-03-26T16:07:30.785126Z","shell.execute_reply.started":"2024-03-26T16:07:30.774057Z","shell.execute_reply":"2024-03-26T16:07:30.784212Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-dataset/Housing.csv\n/kaggle/input/kingcountyhousing/KC_housing_data.csv\n/kaggle/input/final-house/house.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# before you can use a data set, it has to be in your data space, see the browser on the upper right side\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:07:35.134888Z","iopub.execute_input":"2024-03-26T16:07:35.135724Z","iopub.status.idle":"2024-03-26T16:07:35.143329Z","shell.execute_reply.started":"2024-03-26T16:07:35.135688Z","shell.execute_reply":"2024-03-26T16:07:35.142459Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/input/housing-prices-dataset/Housing.csv\n/kaggle/input/kingcountyhousing/KC_housing_data.csv\n/kaggle/input/final-house/house.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Install pyspark in this environment","metadata":{}},{"cell_type":"code","source":"#install Apache Spark\n!pip install pyspark --quiet","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:07:50.416850Z","iopub.execute_input":"2024-03-26T16:07:50.417283Z","iopub.status.idle":"2024-03-26T16:08:05.891735Z","shell.execute_reply.started":"2024-03-26T16:07:50.417250Z","shell.execute_reply":"2024-03-26T16:08:05.889764Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Install packages\n\nMost \"standard\" packages seem to be available on Kaggle","metadata":{}},{"cell_type":"code","source":"#Generic Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Apache Spark Libraries\nimport pyspark\nfrom pyspark.sql import SparkSession\n\n#Apache Spark ML CLassifier Libraries\nfrom pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,NaiveBayes\n\n#Apache Spark Evaluation Library\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n#Apache Spark Features libraries\nfrom pyspark.ml.feature import StandardScaler,StringIndexer, VectorAssembler, VectorIndexer, OneHotEncoder\n\n#Apache Spark Pipelin Library\nfrom pyspark.ml import Pipeline\n\n# Apache Spark `DenseVector`\nfrom pyspark.ml.linalg import DenseVector\n\n#Data Split Libraries\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\n\n#Tabulating Data\nfrom tabulate import tabulate\n\n#Garbage\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:08:14.007300Z","iopub.execute_input":"2024-03-26T16:08:14.007709Z","iopub.status.idle":"2024-03-26T16:08:14.015762Z","shell.execute_reply.started":"2024-03-26T16:08:14.007679Z","shell.execute_reply":"2024-03-26T16:08:14.014582Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Building Spark Session\nspark = (SparkSession.builder\n                  .appName('Apache Spark Beginner Tutorial')\n                  .config(\"spark.executor.memory\", \"1G\")\n                  .config(\"spark.executor.cores\",\"4\")\n                  .getOrCreate())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:08:16.656492Z","iopub.execute_input":"2024-03-26T16:08:16.656926Z","iopub.status.idle":"2024-03-26T16:08:16.674158Z","shell.execute_reply.started":"2024-03-26T16:08:16.656892Z","shell.execute_reply":"2024-03-26T16:08:16.672573Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"24/03/26 16:08:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I'm not sure just what the setLogLevel function below does,   It may make sense to turn off this operation","metadata":{}},{"cell_type":"code","source":"spark.sparkContext.setLogLevel('INFO')","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:08:20.229598Z","iopub.execute_input":"2024-03-26T16:08:20.230257Z","iopub.status.idle":"2024-03-26T16:08:20.239081Z","shell.execute_reply.started":"2024-03-26T16:08:20.230225Z","shell.execute_reply":"2024-03-26T16:08:20.236947Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Check the Spark version level,   this looks straightforward","metadata":{}},{"cell_type":"code","source":"spark.version","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:08:23.646514Z","iopub.execute_input":"2024-03-26T16:08:23.646947Z","iopub.status.idle":"2024-03-26T16:08:23.657155Z","shell.execute_reply.started":"2024-03-26T16:08:23.646916Z","shell.execute_reply":"2024-03-26T16:08:23.655840Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'3.5.1'"},"metadata":{}}]},{"cell_type":"code","source":"#This is just a test loading of a kaggle data set into a pandas data set\n# You have to have the data sets in your kaggle directory to load them,  there is a \"Data\" load data option on the upper right side of\n# the kaggle notebook system\n\ndf = pd.read_csv('/kaggle/input/iris/Iris.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:12:42.739756Z","iopub.execute_input":"2024-03-26T16:12:42.740158Z","iopub.status.idle":"2024-03-26T16:12:42.793464Z","shell.execute_reply.started":"2024-03-26T16:12:42.740126Z","shell.execute_reply":"2024-03-26T16:12:42.792528Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:12:46.676692Z","iopub.execute_input":"2024-03-26T16:12:46.677567Z","iopub.status.idle":"2024-03-26T16:12:46.704167Z","shell.execute_reply.started":"2024-03-26T16:12:46.677528Z","shell.execute_reply":"2024-03-26T16:12:46.702833Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Okay, the basic data load operation worked\n\nNow, we will load the data set into spark.   The load function looks fairly standard, note the syntax","metadata":{}},{"cell_type":"code","source":"url = '/kaggle/input/iris/Iris.csv'\n\ndata = spark.read.format(\"csv\") \\\n       .option(\"header\", \"true\") \\\n       .option(\"inferSchema\",\"true\")\\\n       .load(url) \n\ndata.cache() #for faster re-use","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:10.849462Z","iopub.execute_input":"2024-03-26T16:13:10.849895Z","iopub.status.idle":"2024-03-26T16:13:11.217049Z","shell.execute_reply.started":"2024-03-26T16:13:10.849863Z","shell.execute_reply":"2024-03-26T16:13:11.215842Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"24/03/26 16:13:10 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n24/03/26 16:13:10 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n24/03/26 16:13:10 INFO FileSourceStrategy: Pushed Filters: \n24/03/26 16:13:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#4598, None)) > 0)\n24/03/26 16:13:10 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 200.1 KiB, free 433.2 MiB)\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 433.2 MiB)\n24/03/26 16:13:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on b2edbf16b081:40551 (size: 34.4 KiB, free: 433.9 MiB)\n24/03/26 16:13:11 INFO SparkContext: Created broadcast 23 from load at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n24/03/26 16:13:11 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:11 INFO DAGScheduler: Got job 20 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:11 INFO DAGScheduler: Final stage: ResultStage 24 (load at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:11 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:11 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:11 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[95] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 13.5 KiB, free 433.2 MiB)\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.2 MiB)\n24/03/26 16:13:11 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on b2edbf16b081:40551 (size: 6.4 KiB, free: 433.9 MiB)\n24/03/26 16:13:11 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[95] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n24/03/26 16:13:11 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 25) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:13:11 INFO Executor: Running task 0.0 in stage 24.0 (TID 25)\n24/03/26 16:13:11 INFO FileScanRDD: Reading File path: file:///kaggle/input/iris/Iris.csv, range: 0-5107, partition values: [empty row]\n24/03/26 16:13:11 INFO Executor: Finished task 0.0 in stage 24.0 (TID 25). 1613 bytes result sent to driver\n24/03/26 16:13:11 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 25) in 23 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n24/03/26 16:13:11 INFO DAGScheduler: ResultStage 24 (load at NativeMethodAccessorImpl.java:0) finished in 0.036 s\n24/03/26 16:13:11 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished\n24/03/26 16:13:11 INFO DAGScheduler: Job 20 finished: load at NativeMethodAccessorImpl.java:0, took 0.041685 s\n24/03/26 16:13:11 INFO FileSourceStrategy: Pushed Filters: \n24/03/26 16:13:11 INFO FileSourceStrategy: Post-Scan Filters: \n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 200.1 KiB, free 433.0 MiB)\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 432.9 MiB)\n24/03/26 16:13:11 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on b2edbf16b081:40551 (size: 34.4 KiB, free: 433.8 MiB)\n24/03/26 16:13:11 INFO SparkContext: Created broadcast 25 from load at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n24/03/26 16:13:11 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:11 INFO DAGScheduler: Got job 21 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:11 INFO DAGScheduler: Final stage: ResultStage 25 (load at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:11 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:11 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:11 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[101] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.7 KiB, free 432.9 MiB)\n24/03/26 16:13:11 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 432.9 MiB)\n24/03/26 16:13:11 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on b2edbf16b081:40551 (size: 12.8 KiB, free: 433.8 MiB)\n24/03/26 16:13:11 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[101] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n24/03/26 16:13:11 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 26) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:13:11 INFO Executor: Running task 0.0 in stage 25.0 (TID 26)\n24/03/26 16:13:11 INFO FileScanRDD: Reading File path: file:///kaggle/input/iris/Iris.csv, range: 0-5107, partition values: [empty row]\n24/03/26 16:13:11 INFO Executor: Finished task 0.0 in stage 25.0 (TID 26). 1684 bytes result sent to driver\n24/03/26 16:13:11 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 26) in 36 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n24/03/26 16:13:11 INFO DAGScheduler: ResultStage 25 (load at NativeMethodAccessorImpl.java:0) finished in 0.048 s\n24/03/26 16:13:11 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n24/03/26 16:13:11 INFO DAGScheduler: Job 21 finished: load at NativeMethodAccessorImpl.java:0, took 0.052747 s\n24/03/26 16:13:11 INFO FileSourceStrategy: Pushed Filters: \n24/03/26 16:13:11 INFO FileSourceStrategy: Post-Scan Filters: \n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"DataFrame[Id: int, SepalLengthCm: double, SepalWidthCm: double, PetalLengthCm: double, PetalWidthCm: double, Species: string]"},"metadata":{}}]},{"cell_type":"code","source":"#Total records \ndata.count()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:17.918515Z","iopub.execute_input":"2024-03-26T16:13:17.918936Z","iopub.status.idle":"2024-03-26T16:13:18.257912Z","shell.execute_reply.started":"2024-03-26T16:13:17.918903Z","shell.execute_reply":"2024-03-26T16:13:18.256635Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"24/03/26 16:13:17 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 200.0 KiB, free 432.7 MiB)\n24/03/26 16:13:17 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 432.7 MiB)\n24/03/26 16:13:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on b2edbf16b081:40551 (size: 34.4 KiB, free: 433.8 MiB)\n24/03/26 16:13:17 INFO SparkContext: Created broadcast 27 from count at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n24/03/26 16:13:17 INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:17 INFO DAGScheduler: Final stage: ResultStage 26 (count at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:17 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:17 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:17 INFO DAGScheduler: Submitting ResultStage 26 (FileScan csv [Id#4615,SepalLengthCm#4616,SepalWidthCm#4617,PetalLengthCm#4618,PetalWidthCm#4619,Species#4620] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/kaggle/input/iris/Iris.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Id:int,SepalLengthCm:double,SepalWidthCm:double,PetalLengthCm:double,PetalWidthCm:double,S...\n MapPartitionsRDD[105] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:17 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 14.6 KiB, free 432.6 MiB)\n24/03/26 16:13:17 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.6 MiB)\n24/03/26 16:13:17 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on b2edbf16b081:40551 (size: 7.4 KiB, free: 433.8 MiB)\n24/03/26 16:13:17 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (FileScan csv [Id#4615,SepalLengthCm#4616,SepalWidthCm#4617,PetalLengthCm#4618,PetalWidthCm#4619,Species#4620] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/kaggle/input/iris/Iris.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Id:int,SepalLengthCm:double,SepalWidthCm:double,PetalLengthCm:double,PetalWidthCm:double,S...\n MapPartitionsRDD[105] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:17 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n24/03/26 16:13:17 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 27) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:13:17 INFO Executor: Running task 0.0 in stage 26.0 (TID 27)\n24/03/26 16:13:18 INFO FileScanRDD: Reading File path: file:///kaggle/input/iris/Iris.csv, range: 0-5107, partition values: [empty row]\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 14.495373 ms\n24/03/26 16:13:18 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 5.9 KiB, free 432.6 MiB)\n24/03/26 16:13:18 INFO BlockManagerInfo: Added rdd_105_0 in memory on b2edbf16b081:40551 (size: 5.9 KiB, free: 433.8 MiB)\n24/03/26 16:13:18 INFO Executor: 1 block locks were not released by task 0.0 in stage 26.0 (TID 27)\n[rdd_105_0]\n24/03/26 16:13:18 INFO Executor: Finished task 0.0 in stage 26.0 (TID 27). 1373 bytes result sent to driver\n24/03/26 16:13:18 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 27) in 67 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n24/03/26 16:13:18 INFO DAGScheduler: ResultStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0.081 s\n24/03/26 16:13:18 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 10.449218 ms\n24/03/26 16:13:18 INFO DAGScheduler: Registering RDD 110 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4\n24/03/26 16:13:18 INFO DAGScheduler: Got map stage job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:18 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:18 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:18 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:18 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:18 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 22.5 KiB, free 432.6 MiB)\n24/03/26 16:13:18 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 432.6 MiB)\n24/03/26 16:13:18 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on b2edbf16b081:40551 (size: 10.5 KiB, free: 433.8 MiB)\n24/03/26 16:13:18 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n24/03/26 16:13:18 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 28) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:13:18 INFO Executor: Running task 0.0 in stage 27.0 (TID 28)\n24/03/26 16:13:18 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 12.320557 ms\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 8.496241 ms\n24/03/26 16:13:18 INFO Executor: Finished task 0.0 in stage 27.0 (TID 28). 2156 bytes result sent to driver\n24/03/26 16:13:18 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 28) in 42 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n24/03/26 16:13:18 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.055 s\n24/03/26 16:13:18 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:13:18 INFO DAGScheduler: running: Set()\n24/03/26 16:13:18 INFO DAGScheduler: waiting: Set()\n24/03/26 16:13:18 INFO DAGScheduler: failed: Set()\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 10.394732 ms\n24/03/26 16:13:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:18 INFO DAGScheduler: Got job 24 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:18 INFO DAGScheduler: Final stage: ResultStage 29 (count at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)\n24/03/26 16:13:18 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:18 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:18 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 432.6 MiB)\n24/03/26 16:13:18 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 432.6 MiB)\n24/03/26 16:13:18 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on b2edbf16b081:40551 (size: 6.0 KiB, free: 433.8 MiB)\n24/03/26 16:13:18 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n24/03/26 16:13:18 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:13:18 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)\n24/03/26 16:13:18 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n24/03/26 16:13:18 INFO CodeGenerator: Code generated in 9.506855 ms\n24/03/26 16:13:18 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 4038 bytes result sent to driver\n24/03/26 16:13:18 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 27 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n24/03/26 16:13:18 INFO DAGScheduler: ResultStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0.039 s\n24/03/26 16:13:18 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n24/03/26 16:13:18 INFO DAGScheduler: Job 24 finished: count at NativeMethodAccessorImpl.java:0, took 0.043630 s\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"150"},"metadata":{}}]},{"cell_type":"markdown","source":"We can take a look at how Spark is storing the data internally,  note the strong similarity to a SQL style data table schema\n\nThe data storage in Spark looks a lot like an SQL database,   Spark is meant to work with distributed databases,  particularly Apache Hive","metadata":{}},{"cell_type":"code","source":"#Data Type\ndata.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:24.693971Z","iopub.execute_input":"2024-03-26T16:13:24.694377Z","iopub.status.idle":"2024-03-26T16:13:24.702332Z","shell.execute_reply.started":"2024-03-26T16:13:24.694339Z","shell.execute_reply":"2024-03-26T16:13:24.700415Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"root\n |-- Id: integer (nullable = true)\n |-- SepalLengthCm: double (nullable = true)\n |-- SepalWidthCm: double (nullable = true)\n |-- PetalLengthCm: double (nullable = true)\n |-- PetalWidthCm: double (nullable = true)\n |-- Species: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"data.show() works like .head() does,   it shows the data table, very much in database style report","metadata":{}},{"cell_type":"code","source":"#Display records\ndata.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:29.054377Z","iopub.execute_input":"2024-03-26T16:13:29.055950Z","iopub.status.idle":"2024-03-26T16:13:29.323664Z","shell.execute_reply.started":"2024-03-26T16:13:29.055891Z","shell.execute_reply":"2024-03-26T16:13:29.322468Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"+---+-------------+------------+-------------+------------+-----------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n+---+-------------+------------+-------------+------------+-----------+\n|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n+---+-------------+------------+-------------+------------+-----------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:13:29 INFO CodeGenerator: Code generated in 12.253547 ms\n24/03/26 16:13:29 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:29 INFO DAGScheduler: Got job 25 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:29 INFO DAGScheduler: Final stage: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:29 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:29 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:29 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:29 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 22.2 KiB, free 432.6 MiB)\n24/03/26 16:13:29 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 432.5 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on b2edbf16b081:40551 (size: 9.9 KiB, free: 433.7 MiB)\n24/03/26 16:13:29 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:29 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n24/03/26 16:13:29 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:13:29 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)\n24/03/26 16:13:29 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:13:29 INFO CodeGenerator: Code generated in 16.000333 ms\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_29_piece0 on b2edbf16b081:40551 in memory (size: 10.5 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO CodeGenerator: Code generated in 87.241017 ms\n24/03/26 16:13:29 INFO Executor: 1 block locks were not released by task 0.0 in stage 30.0 (TID 30)\n[rdd_105_0]\n24/03/26 16:13:29 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 1928 bytes result sent to driver\n24/03/26 16:13:29 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 126 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:29 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n24/03/26 16:13:29 INFO DAGScheduler: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 0.138 s\n24/03/26 16:13:29 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n24/03/26 16:13:29 INFO DAGScheduler: Job 25 finished: showString at NativeMethodAccessorImpl.java:0, took 0.145393 s\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_22_piece0 on b2edbf16b081:40551 in memory (size: 7.9 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO CodeGenerator: Code generated in 18.909364 ms\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_23_piece0 on b2edbf16b081:40551 in memory (size: 34.4 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on b2edbf16b081:40551 in memory (size: 6.0 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_28_piece0 on b2edbf16b081:40551 in memory (size: 7.4 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_17_piece0 on b2edbf16b081:40551 in memory (size: 23.6 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_16_piece0 on b2edbf16b081:40551 in memory (size: 12.2 KiB, free: 433.8 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_26_piece0 on b2edbf16b081:40551 in memory (size: 12.8 KiB, free: 433.9 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_15_piece0 on b2edbf16b081:40551 in memory (size: 11.1 KiB, free: 433.9 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_19_piece0 on b2edbf16b081:40551 in memory (size: 21.4 KiB, free: 433.9 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_21_piece0 on b2edbf16b081:40551 in memory (size: 13.5 KiB, free: 433.9 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_25_piece0 on b2edbf16b081:40551 in memory (size: 34.4 KiB, free: 433.9 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_20_piece0 on b2edbf16b081:40551 in memory (size: 22.9 KiB, free: 434.0 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_24_piece0 on b2edbf16b081:40551 in memory (size: 6.4 KiB, free: 434.0 MiB)\n24/03/26 16:13:29 INFO BlockManagerInfo: Removed broadcast_18_piece0 on b2edbf16b081:40551 in memory (size: 25.6 KiB, free: 434.0 MiB)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here is a groupby operation","metadata":{}},{"cell_type":"code","source":"#Records per Species\ndata.groupBy('species').count().show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:33.622972Z","iopub.execute_input":"2024-03-26T16:13:33.624283Z","iopub.status.idle":"2024-03-26T16:13:33.966112Z","shell.execute_reply.started":"2024-03-26T16:13:33.624228Z","shell.execute_reply":"2024-03-26T16:13:33.964906Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"24/03/26 16:13:33 INFO CodeGenerator: Code generated in 30.492688 ms\n24/03/26 16:13:33 INFO DAGScheduler: Registering RDD 123 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5\n24/03/26 16:13:33 INFO DAGScheduler: Got map stage job 26 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:33 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:33 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:33 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:33 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[123] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:33 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 42.5 KiB, free 433.5 MiB)\n24/03/26 16:13:33 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.5 MiB)\n24/03/26 16:13:33 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on b2edbf16b081:40551 (size: 19.6 KiB, free: 434.0 MiB)\n24/03/26 16:13:33 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[123] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:33 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n24/03/26 16:13:33 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:13:33 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)\n24/03/26 16:13:33 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:13:33 INFO CodeGenerator: Code generated in 29.409494 ms\n24/03/26 16:13:33 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2676 bytes result sent to driver\n24/03/26 16:13:33 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 70 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:33 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n24/03/26 16:13:33 INFO DAGScheduler: ShuffleMapStage 31 (showString at NativeMethodAccessorImpl.java:0) finished in 0.081 s\n24/03/26 16:13:33 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:13:33 INFO DAGScheduler: running: Set()\n24/03/26 16:13:33 INFO DAGScheduler: waiting: Set()\n24/03/26 16:13:33 INFO DAGScheduler: failed: Set()\n24/03/26 16:13:33 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n24/03/26 16:13:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n24/03/26 16:13:33 INFO CodeGenerator: Code generated in 21.123826 ms\n24/03/26 16:13:33 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:33 INFO DAGScheduler: Got job 27 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:33 INFO DAGScheduler: Final stage: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)\n24/03/26 16:13:33 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:33 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[126] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:33 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 45.1 KiB, free 433.5 MiB)\n24/03/26 16:13:33 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.9 KiB, free 433.5 MiB)\n24/03/26 16:13:33 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on b2edbf16b081:40551 (size: 20.9 KiB, free: 434.0 MiB)\n24/03/26 16:13:33 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[126] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:33 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n24/03/26 16:13:33 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 32) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:13:33 INFO Executor: Running task 0.0 in stage 33.0 (TID 32)\n24/03/26 16:13:33 INFO ShuffleBlockFetcherIterator: Getting 1 (240.0 B) non-empty blocks including 1 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:13:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n","output_type":"stream"},{"name":"stdout","text":"+---------------+-----+\n|        species|count|\n+---------------+-----+\n| Iris-virginica|   50|\n|    Iris-setosa|   50|\n|Iris-versicolor|   50|\n+---------------+-----+\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:13:33 INFO CodeGenerator: Code generated in 15.625202 ms\n24/03/26 16:13:33 INFO Executor: Finished task 0.0 in stage 33.0 (TID 32). 5138 bytes result sent to driver\n24/03/26 16:13:33 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 32) in 39 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:33 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n24/03/26 16:13:33 INFO DAGScheduler: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 0.051 s\n24/03/26 16:13:33 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n24/03/26 16:13:33 INFO DAGScheduler: Job 27 finished: showString at NativeMethodAccessorImpl.java:0, took 0.058303 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here is a describe() function,  that does the typical data summary operation","metadata":{}},{"cell_type":"code","source":"#Dataset Summary Stats\ndata.describe().show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:13:41.894390Z","iopub.execute_input":"2024-03-26T16:13:41.894865Z","iopub.status.idle":"2024-03-26T16:13:42.961381Z","shell.execute_reply.started":"2024-03-26T16:13:41.894830Z","shell.execute_reply":"2024-03-26T16:13:42.960185Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"24/03/26 16:13:42 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n24/03/26 16:13:42 INFO DAGScheduler: Registering RDD 131 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n24/03/26 16:13:42 INFO DAGScheduler: Got map stage job 28 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:42 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:42 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:13:42 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:42 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[131] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:42 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 50.6 KiB, free 433.4 MiB)\n24/03/26 16:13:42 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 433.4 MiB)\n24/03/26 16:13:42 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on b2edbf16b081:40551 (size: 20.5 KiB, free: 433.9 MiB)\n24/03/26 16:13:42 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[131] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:42 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n24/03/26 16:13:42 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 33) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:13:42 INFO Executor: Running task 0.0 in stage 34.0 (TID 33)\n24/03/26 16:13:42 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 15.195649 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 74.751113 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 6.688566 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 18.665738 ms\n24/03/26 16:13:42 INFO Executor: Finished task 0.0 in stage 34.0 (TID 33). 1956 bytes result sent to driver\n24/03/26 16:13:42 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 33) in 283 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:42 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n24/03/26 16:13:42 INFO DAGScheduler: ShuffleMapStage 34 (showString at NativeMethodAccessorImpl.java:0) finished in 0.335 s\n24/03/26 16:13:42 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:13:42 INFO DAGScheduler: running: Set()\n24/03/26 16:13:42 INFO DAGScheduler: waiting: Set()\n24/03/26 16:13:42 INFO DAGScheduler: failed: Set()\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 16.878107 ms\n24/03/26 16:13:42 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n24/03/26 16:13:42 INFO DAGScheduler: Got job 29 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:13:42 INFO DAGScheduler: Final stage: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:13:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)\n24/03/26 16:13:42 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:13:42 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:13:42 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 100.6 KiB, free 433.3 MiB)\n24/03/26 16:13:42 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 433.3 MiB)\n24/03/26 16:13:42 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on b2edbf16b081:40551 (size: 33.3 KiB, free: 433.9 MiB)\n24/03/26 16:13:42 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:13:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:13:42 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n24/03/26 16:13:42 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 34) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:13:42 INFO Executor: Running task 0.0 in stage 36.0 (TID 34)\n24/03/26 16:13:42 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:13:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n|summary|                Id|     SepalLengthCm|       SepalWidthCm|     PetalLengthCm|      PetalWidthCm|       Species|\n+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n|  count|               150|               150|                150|               150|               150|           150|\n|   mean|              75.5| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          NULL|\n| stddev|43.445367992456916|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          NULL|\n|    min|                 1|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n|    max|               150|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:13:42 INFO CodeGenerator: Code generated in 59.797185 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 28.361492 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 43.479029 ms\n24/03/26 16:13:42 INFO CodeGenerator: Code generated in 15.96853 ms\n24/03/26 16:13:42 INFO Executor: Finished task 0.0 in stage 36.0 (TID 34). 4765 bytes result sent to driver\n24/03/26 16:13:42 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 34) in 302 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:13:42 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n24/03/26 16:13:42 INFO DAGScheduler: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 0.350 s\n24/03/26 16:13:42 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:13:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n24/03/26 16:13:42 INFO DAGScheduler: Job 29 finished: showString at NativeMethodAccessorImpl.java:0, took 0.355305 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The species names are text, and we know ML models need to have integer codings\n\nThe StringIndexer in Spark takes care of this","metadata":{}},{"cell_type":"code","source":"#String Indexing the Species column\nSIndexer = StringIndexer(inputCol='Species', outputCol='species_indx')\ndata = SIndexer.fit(data).transform(data)\n\n#Inspect the dataset\ndata.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:14:10.251356Z","iopub.execute_input":"2024-03-26T16:14:10.252067Z","iopub.status.idle":"2024-03-26T16:14:11.258417Z","shell.execute_reply.started":"2024-03-26T16:14:10.252032Z","shell.execute_reply":"2024-03-26T16:14:11.257196Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"24/03/26 16:14:10 INFO DAGScheduler: Registering RDD 140 (collect at StringIndexer.scala:204) as input to shuffle 7\n24/03/26 16:14:10 INFO DAGScheduler: Got map stage job 30 (collect at StringIndexer.scala:204) with 1 output partitions\n24/03/26 16:14:10 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at StringIndexer.scala:204)\n24/03/26 16:14:10 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:14:10 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:14:10 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[140] at collect at StringIndexer.scala:204), which has no missing parents\n24/03/26 16:14:10 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 32.5 KiB, free 433.2 MiB)\n24/03/26 16:14:10 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 433.2 MiB)\n24/03/26 16:14:10 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on b2edbf16b081:40551 (size: 15.2 KiB, free: 433.9 MiB)\n24/03/26 16:14:10 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:14:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[140] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:14:10 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n24/03/26 16:14:10 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 35) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:14:10 INFO Executor: Running task 0.0 in stage 37.0 (TID 35)\n24/03/26 16:14:10 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 5.859694 ms\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 4.370091 ms\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 6.080595 ms\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 14.804407 ms\n24/03/26 16:14:10 INFO Executor: Finished task 0.0 in stage 37.0 (TID 35). 2204 bytes result sent to driver\n24/03/26 16:14:10 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 35) in 341 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:14:10 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n24/03/26 16:14:10 INFO DAGScheduler: ShuffleMapStage 37 (collect at StringIndexer.scala:204) finished in 0.370 s\n24/03/26 16:14:10 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:14:10 INFO DAGScheduler: running: Set()\n24/03/26 16:14:10 INFO DAGScheduler: waiting: Set()\n24/03/26 16:14:10 INFO DAGScheduler: failed: Set()\n24/03/26 16:14:10 INFO SparkContext: Starting job: collect at StringIndexer.scala:204\n24/03/26 16:14:10 INFO DAGScheduler: Got job 31 (collect at StringIndexer.scala:204) with 1 output partitions\n24/03/26 16:14:10 INFO DAGScheduler: Final stage: ResultStage 39 (collect at StringIndexer.scala:204)\n24/03/26 16:14:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)\n24/03/26 16:14:10 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:14:10 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[143] at collect at StringIndexer.scala:204), which has no missing parents\n24/03/26 16:14:10 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 37.6 KiB, free 433.2 MiB)\n24/03/26 16:14:10 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 433.2 MiB)\n24/03/26 16:14:10 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on b2edbf16b081:40551 (size: 17.8 KiB, free: 433.9 MiB)\n24/03/26 16:14:10 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:14:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[143] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:14:10 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n24/03/26 16:14:10 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 36) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:14:10 INFO Executor: Running task 0.0 in stage 39.0 (TID 36)\n24/03/26 16:14:10 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:14:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 11.747599 ms\n24/03/26 16:14:10 INFO Executor: Finished task 0.0 in stage 39.0 (TID 36). 4904 bytes result sent to driver\n24/03/26 16:14:10 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 36) in 97 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:14:10 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n24/03/26 16:14:10 INFO DAGScheduler: ResultStage 39 (collect at StringIndexer.scala:204) finished in 0.105 s\n24/03/26 16:14:10 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:14:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished\n24/03/26 16:14:10 INFO DAGScheduler: Job 31 finished: collect at StringIndexer.scala:204, took 0.109197 s\n24/03/26 16:14:10 INFO CodeGenerator: Code generated in 11.688254 ms\n","output_type":"stream"},{"name":"stdout","text":"+---+-------------+------------+-------------+------------+-----------+------------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|species_indx|\n+---+-------------+------------+-------------+------------+-----------+------------+\n|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|         0.0|\n|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|         0.0|\n|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|         0.0|\n|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|         0.0|\n|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|         0.0|\n+---+-------------+------------+-------------+------------+-----------+------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:14:11 INFO CodeGenerator: Code generated in 21.656638 ms\n24/03/26 16:14:11 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n24/03/26 16:14:11 INFO DAGScheduler: Got job 32 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/03/26 16:14:11 INFO DAGScheduler: Final stage: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0)\n24/03/26 16:14:11 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:14:11 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:14:11 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[148] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/03/26 16:14:11 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 38.9 KiB, free 433.1 MiB)\n24/03/26 16:14:11 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 433.1 MiB)\n24/03/26 16:14:11 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on b2edbf16b081:40551 (size: 18.0 KiB, free: 433.8 MiB)\n24/03/26 16:14:11 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:14:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[148] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:14:11 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n24/03/26 16:14:11 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 37) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:14:11 INFO Executor: Running task 0.0 in stage 40.0 (TID 37)\n24/03/26 16:14:11 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:14:11 INFO CodeGenerator: Code generated in 13.986763 ms\n24/03/26 16:14:11 INFO Executor: 1 block locks were not released by task 0.0 in stage 40.0 (TID 37)\n[rdd_105_0]\n24/03/26 16:14:11 INFO Executor: Finished task 0.0 in stage 40.0 (TID 37). 1937 bytes result sent to driver\n24/03/26 16:14:11 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 37) in 68 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:14:11 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n24/03/26 16:14:11 INFO DAGScheduler: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0) finished in 0.079 s\n24/03/26 16:14:11 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:14:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished\n24/03/26 16:14:11 INFO DAGScheduler: Job 32 finished: showString at NativeMethodAccessorImpl.java:0, took 0.084010 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We are going to do a classic data select of the data,  much like an sql select, to reformat the data a bit, reordering columns and removing\nthe text species name","metadata":{}},{"cell_type":"code","source":"#creating a seperate dataframe with re-ordered columns\ndf = data.select(\"species_indx\",\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\")\n\n#Inspect the dataframe\ndf.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:16:49.748980Z","iopub.execute_input":"2024-03-26T16:16:49.749434Z","iopub.status.idle":"2024-03-26T16:16:49.955440Z","shell.execute_reply.started":"2024-03-26T16:16:49.749403Z","shell.execute_reply":"2024-03-26T16:16:49.954225Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"+------------+-------------+------------+-------------+------------+\n|species_indx|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|\n+------------+-------------+------------+-------------+------------+\n|         0.0|          5.1|         3.5|          1.4|         0.2|\n|         0.0|          4.9|         3.0|          1.4|         0.2|\n|         0.0|          4.7|         3.2|          1.3|         0.2|\n|         0.0|          4.6|         3.1|          1.5|         0.2|\n|         0.0|          5.0|         3.6|          1.4|         0.2|\n+------------+-------------+------------+-------------+------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:16:49 INFO CodeGenerator: Code generated in 13.251362 ms\n24/03/26 16:16:49 INFO SparkContext: Starting job: showString at <unknown>:0\n24/03/26 16:16:49 INFO DAGScheduler: Got job 33 (showString at <unknown>:0) with 1 output partitions\n24/03/26 16:16:49 INFO DAGScheduler: Final stage: ResultStage 41 (showString at <unknown>:0)\n24/03/26 16:16:49 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:16:49 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:16:49 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[153] at showString at <unknown>:0), which has no missing parents\n24/03/26 16:16:49 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 38.4 KiB, free 433.1 MiB)\n24/03/26 16:16:49 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 433.0 MiB)\n24/03/26 16:16:49 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on b2edbf16b081:40551 (size: 17.9 KiB, free: 433.8 MiB)\n24/03/26 16:16:49 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:16:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[153] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:16:49 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n24/03/26 16:16:49 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 38) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:16:49 INFO Executor: Running task 0.0 in stage 41.0 (TID 38)\n24/03/26 16:16:49 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:16:49 INFO CodeGenerator: Code generated in 18.998633 ms\n24/03/26 16:16:49 INFO CodeGenerator: Code generated in 11.981503 ms\n24/03/26 16:16:49 INFO Executor: 1 block locks were not released by task 0.0 in stage 41.0 (TID 38)\n[rdd_105_0]\n24/03/26 16:16:49 INFO Executor: Finished task 0.0 in stage 41.0 (TID 38). 1827 bytes result sent to driver\n24/03/26 16:16:49 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 38) in 66 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:16:49 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n24/03/26 16:16:49 INFO DAGScheduler: ResultStage 41 (showString at <unknown>:0) finished in 0.080 s\n24/03/26 16:16:49 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:16:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished\n24/03/26 16:16:49 INFO DAGScheduler: Job 33 finished: showString at <unknown>:0, took 0.087052 s\n24/03/26 16:16:49 INFO CodeGenerator: Code generated in 5.471161 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We are now going to rearrange the data, mapping it as the first column (our target) and then a Spark Dense Vector","metadata":{}},{"cell_type":"code","source":"# Define the `input_data` as Dense Vector\ninput_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:16:57.261784Z","iopub.execute_input":"2024-03-26T16:16:57.262182Z","iopub.status.idle":"2024-03-26T16:16:57.315706Z","shell.execute_reply.started":"2024-03-26T16:16:57.262153Z","shell.execute_reply":"2024-03-26T16:16:57.314318Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"24/03/26 16:16:57 INFO CodeGenerator: Code generated in 6.876369 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Create a new data frame, using the target as the index, and the DenseVector as the features","metadata":{}},{"cell_type":"code","source":"# Creating a new Indexed Dataframe\ndf_indx = spark.createDataFrame(input_data, [\"label\", \"features\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:02.222591Z","iopub.execute_input":"2024-03-26T16:17:02.223047Z","iopub.status.idle":"2024-03-26T16:17:03.372053Z","shell.execute_reply.started":"2024-03-26T16:17:02.223012Z","shell.execute_reply":"2024-03-26T16:17:03.370901Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"24/03/26 16:17:02 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181\n24/03/26 16:17:02 INFO DAGScheduler: Got job 34 (runJob at PythonRDD.scala:181) with 1 output partitions\n24/03/26 16:17:02 INFO DAGScheduler: Final stage: ResultStage 42 (runJob at PythonRDD.scala:181)\n24/03/26 16:17:02 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:02 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:02 INFO DAGScheduler: Submitting ResultStage 42 (PythonRDD[161] at RDD at PythonRDD.scala:53), which has no missing parents\n24/03/26 16:17:02 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 45.7 KiB, free 433.0 MiB)\n24/03/26 16:17:02 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 433.0 MiB)\n24/03/26 16:17:02 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on b2edbf16b081:40551 (size: 21.7 KiB, free: 433.8 MiB)\n24/03/26 16:17:02 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (PythonRDD[161] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:02 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n24/03/26 16:17:02 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 39) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:02 INFO Executor: Running task 0.0 in stage 42.0 (TID 39)\n24/03/26 16:17:02 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:02 INFO CodeGenerator: Code generated in 9.611076 ms\n24/03/26 16:17:03 INFO PythonRunner: Times: total = 1017, boot = 7, init = 1010, finish = 0\n24/03/26 16:17:03 INFO Executor: Finished task 0.0 in stage 42.0 (TID 39). 2000 bytes result sent to driver\n24/03/26 16:17:03 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 39) in 1063 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:03 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n24/03/26 16:17:03 INFO DAGScheduler: ResultStage 42 (runJob at PythonRDD.scala:181) finished in 1.073 s\n24/03/26 16:17:03 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished\n24/03/26 16:17:03 INFO DAGScheduler: Job 34 finished: runJob at PythonRDD.scala:181, took 1.077208 s\n                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#view the indexed dataframe\ndf_indx.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:07.204722Z","iopub.execute_input":"2024-03-26T16:17:07.205849Z","iopub.status.idle":"2024-03-26T16:17:08.395005Z","shell.execute_reply.started":"2024-03-26T16:17:07.205806Z","shell.execute_reply":"2024-03-26T16:17:08.393654Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"24/03/26 16:17:07 INFO CodeGenerator: Code generated in 41.281984 ms\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_31_piece0 on b2edbf16b081:40551 in memory (size: 9.9 KiB, free: 433.8 MiB)\n24/03/26 16:17:07 INFO SparkContext: Starting job: showString at <unknown>:0\n24/03/26 16:17:07 INFO DAGScheduler: Got job 35 (showString at <unknown>:0) with 1 output partitions\n24/03/26 16:17:07 INFO DAGScheduler: Final stage: ResultStage 43 (showString at <unknown>:0)\n24/03/26 16:17:07 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:07 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:07 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[167] at showString at <unknown>:0), which has no missing parents\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_38_piece0 on b2edbf16b081:40551 in memory (size: 18.0 KiB, free: 433.8 MiB)\n24/03/26 16:17:07 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 52.1 KiB, free 433.1 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_34_piece0 on b2edbf16b081:40551 in memory (size: 20.5 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.4 KiB, free 433.1 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on b2edbf16b081:40551 (size: 24.4 KiB, free: 433.8 MiB)\n24/03/26 16:17:07 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[167] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:07 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_32_piece0 on b2edbf16b081:40551 in memory (size: 19.6 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 40) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:07 INFO Executor: Running task 0.0 in stage 43.0 (TID 40)\n24/03/26 16:17:07 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_36_piece0 on b2edbf16b081:40551 in memory (size: 15.2 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_37_piece0 on b2edbf16b081:40551 in memory (size: 17.8 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO CodeGenerator: Code generated in 11.376243 ms\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_33_piece0 on b2edbf16b081:40551 in memory (size: 20.9 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_35_piece0 on b2edbf16b081:40551 in memory (size: 33.3 KiB, free: 433.9 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_39_piece0 on b2edbf16b081:40551 in memory (size: 17.9 KiB, free: 434.0 MiB)\n24/03/26 16:17:07 INFO BlockManagerInfo: Removed broadcast_40_piece0 on b2edbf16b081:40551 in memory (size: 21.7 KiB, free: 434.0 MiB)\n[Stage 43:>                                                         (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+-----+-----------------+\n|label|         features|\n+-----+-----------------+\n|  0.0|[5.1,3.5,1.4,0.2]|\n|  0.0|[4.9,3.0,1.4,0.2]|\n|  0.0|[4.7,3.2,1.3,0.2]|\n|  0.0|[4.6,3.1,1.5,0.2]|\n|  0.0|[5.0,3.6,1.4,0.2]|\n+-----+-----------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:17:08 INFO Executor: Finished task 0.0 in stage 43.0 (TID 40). 2268 bytes result sent to driver\n24/03/26 16:17:08 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 40) in 1055 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n24/03/26 16:17:08 INFO DAGScheduler: ResultStage 43 (showString at <unknown>:0) finished in 1.067 s\n24/03/26 16:17:08 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n24/03/26 16:17:08 INFO DAGScheduler: Job 35 finished: showString at <unknown>:0, took 1.075178 s\n                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"We will fit some ML models, so we need to standardize the features","metadata":{}},{"cell_type":"code","source":"#Initialize Standard Scaler\nstdScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n\n#Fit the Standard Scaler to the indexed Dataframe\nscaler = stdScaler.fit(df_indx)\n\n#Transform the dataframe\ndf_scaled =scaler.transform(df_indx)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:15.396973Z","iopub.execute_input":"2024-03-26T16:17:15.397748Z","iopub.status.idle":"2024-03-26T16:17:17.039907Z","shell.execute_reply.started":"2024-03-26T16:17:15.397698Z","shell.execute_reply":"2024-03-26T16:17:17.038562Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"24/03/26 16:17:15 INFO CodeGenerator: Code generated in 6.918969 ms\n24/03/26 16:17:15 INFO DAGScheduler: Registering RDD 170 (first at StandardScaler.scala:113) as input to shuffle 8\n24/03/26 16:17:15 INFO DAGScheduler: Got map stage job 36 (first at StandardScaler.scala:113) with 1 output partitions\n24/03/26 16:17:15 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (first at StandardScaler.scala:113)\n24/03/26 16:17:15 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:15 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:15 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[170] at first at StandardScaler.scala:113), which has no missing parents\n24/03/26 16:17:15 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 60.7 KiB, free 433.5 MiB)\n24/03/26 16:17:15 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 433.4 MiB)\n24/03/26 16:17:15 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on b2edbf16b081:40551 (size: 27.8 KiB, free: 433.9 MiB)\n24/03/26 16:17:15 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[170] at first at StandardScaler.scala:113) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:15 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n24/03/26 16:17:15 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 41) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:15 INFO Executor: Running task 0.0 in stage 44.0 (TID 41)\n24/03/26 16:17:15 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:15 INFO CodeGenerator: Code generated in 8.971508 ms\n24/03/26 16:17:16 INFO PythonRunner: Times: total = 1065, boot = 5, init = 1056, finish = 4\n24/03/26 16:17:16 INFO Executor: Finished task 0.0 in stage 44.0 (TID 41). 2818 bytes result sent to driver\n24/03/26 16:17:16 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 41) in 1118 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:16 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n24/03/26 16:17:16 INFO DAGScheduler: ShuffleMapStage 44 (first at StandardScaler.scala:113) finished in 1.135 s\n24/03/26 16:17:16 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:16 INFO DAGScheduler: running: Set()\n24/03/26 16:17:16 INFO DAGScheduler: waiting: Set()\n24/03/26 16:17:16 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:16 INFO CodeGenerator: Code generated in 10.751816 ms\n24/03/26 16:17:16 INFO SparkContext: Starting job: first at StandardScaler.scala:113\n24/03/26 16:17:16 INFO DAGScheduler: Got job 37 (first at StandardScaler.scala:113) with 1 output partitions\n24/03/26 16:17:16 INFO DAGScheduler: Final stage: ResultStage 46 (first at StandardScaler.scala:113)\n24/03/26 16:17:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n24/03/26 16:17:16 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:16 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[174] at first at StandardScaler.scala:113), which has no missing parents\n24/03/26 16:17:16 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 69.0 KiB, free 433.4 MiB)\n24/03/26 16:17:16 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.7 KiB, free 433.4 MiB)\n24/03/26 16:17:16 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on b2edbf16b081:40551 (size: 30.7 KiB, free: 433.9 MiB)\n24/03/26 16:17:16 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[174] at first at StandardScaler.scala:113) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:16 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n24/03/26 16:17:16 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 42) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:17:16 INFO Executor: Running task 0.0 in stage 46.0 (TID 42)\n24/03/26 16:17:16 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n24/03/26 16:17:16 INFO CodeGenerator: Code generated in 10.397666 ms\n24/03/26 16:17:16 INFO CodeGenerator: Code generated in 11.076642 ms\n24/03/26 16:17:16 INFO Executor: Finished task 0.0 in stage 46.0 (TID 42). 5312 bytes result sent to driver\n24/03/26 16:17:16 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 42) in 59 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:16 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n24/03/26 16:17:16 INFO DAGScheduler: ResultStage 46 (first at StandardScaler.scala:113) finished in 0.068 s\n24/03/26 16:17:16 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n24/03/26 16:17:16 INFO DAGScheduler: Job 37 finished: first at StandardScaler.scala:113, took 0.073886 s\n24/03/26 16:17:16 INFO CodeGenerator: Code generated in 6.97068 ms              \n","output_type":"stream"}]},{"cell_type":"code","source":"#Viewing the Scaled Data\ndf_scaled.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:20.142566Z","iopub.execute_input":"2024-03-26T16:17:20.142984Z","iopub.status.idle":"2024-03-26T16:17:20.580786Z","shell.execute_reply.started":"2024-03-26T16:17:20.142953Z","shell.execute_reply":"2024-03-26T16:17:20.579572Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"24/03/26 16:17:20 INFO CodeGenerator: Code generated in 8.475077 ms\n24/03/26 16:17:20 INFO SparkContext: Starting job: showString at <unknown>:0\n24/03/26 16:17:20 INFO DAGScheduler: Got job 38 (showString at <unknown>:0) with 1 output partitions\n24/03/26 16:17:20 INFO DAGScheduler: Final stage: ResultStage 47 (showString at <unknown>:0)\n24/03/26 16:17:20 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:20 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:20 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[176] at showString at <unknown>:0), which has no missing parents\n24/03/26 16:17:20 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 57.9 KiB, free 433.3 MiB)\n24/03/26 16:17:20 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 433.3 MiB)\n24/03/26 16:17:20 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on b2edbf16b081:40551 (size: 26.3 KiB, free: 433.9 MiB)\n24/03/26 16:17:20 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[176] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:20 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n24/03/26 16:17:20 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 43) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:20 INFO Executor: Running task 0.0 in stage 47.0 (TID 43)\n24/03/26 16:17:20 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:20 INFO CodeGenerator: Code generated in 11.679727 ms\n","output_type":"stream"},{"name":"stdout","text":"+-----+-----------------+--------------------+\n|label|         features|     features_scaled|\n+-----+-----------------+--------------------+\n|  0.0|[5.1,3.5,1.4,0.2]|[6.15892840883878...|\n|  0.0|[4.9,3.0,1.4,0.2]|[5.9174018045706,...|\n|  0.0|[4.7,3.2,1.3,0.2]|[5.67587520030241...|\n|  0.0|[4.6,3.1,1.5,0.2]|[5.55511189816831...|\n|  0.0|[5.0,3.6,1.4,0.2]|[6.03816510670469...|\n+-----+-----------------+--------------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:17:20 INFO CodeGenerator: Code generated in 6.390567 ms\n24/03/26 16:17:20 INFO CodeGenerator: Code generated in 25.887627 ms\n24/03/26 16:17:20 INFO Executor: Finished task 0.0 in stage 47.0 (TID 43). 2652 bytes result sent to driver\n24/03/26 16:17:20 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 43) in 346 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:20 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n24/03/26 16:17:20 INFO DAGScheduler: ResultStage 47 (showString at <unknown>:0) finished in 0.362 s\n24/03/26 16:17:20 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n24/03/26 16:17:20 INFO DAGScheduler: Job 38 finished: showString at <unknown>:0, took 0.370365 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#Dropping the Features column\ndf_scaled = df_scaled.drop(\"features\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:31.545308Z","iopub.execute_input":"2024-03-26T16:17:31.545732Z","iopub.status.idle":"2024-03-26T16:17:31.558016Z","shell.execute_reply.started":"2024-03-26T16:17:31.545695Z","shell.execute_reply":"2024-03-26T16:17:31.556898Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Now Create the test and train sets","metadata":{}},{"cell_type":"code","source":"train_data, test_data = df_scaled.randomSplit([0.9, 0.1], seed = 12345)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:37.117678Z","iopub.execute_input":"2024-03-26T16:17:37.118447Z","iopub.status.idle":"2024-03-26T16:17:37.141676Z","shell.execute_reply.started":"2024-03-26T16:17:37.118400Z","shell.execute_reply":"2024-03-26T16:17:37.140536Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#Inspect Training Data\ntrain_data.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:39.628210Z","iopub.execute_input":"2024-03-26T16:17:39.628704Z","iopub.status.idle":"2024-03-26T16:17:40.854041Z","shell.execute_reply.started":"2024-03-26T16:17:39.628665Z","shell.execute_reply":"2024-03-26T16:17:40.852735Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"24/03/26 16:17:39 INFO CodeGenerator: Code generated in 18.898072 ms\n24/03/26 16:17:39 INFO SparkContext: Starting job: showString at <unknown>:0\n24/03/26 16:17:39 INFO DAGScheduler: Got job 39 (showString at <unknown>:0) with 1 output partitions\n24/03/26 16:17:39 INFO DAGScheduler: Final stage: ResultStage 48 (showString at <unknown>:0)\n24/03/26 16:17:39 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:39 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:39 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[178] at showString at <unknown>:0), which has no missing parents\n24/03/26 16:17:39 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 69.4 KiB, free 433.2 MiB)\n24/03/26 16:17:39 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 433.2 MiB)\n24/03/26 16:17:39 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on b2edbf16b081:40551 (size: 31.0 KiB, free: 433.9 MiB)\n24/03/26 16:17:39 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[178] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:39 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n24/03/26 16:17:39 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 44) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:39 INFO Executor: Running task 0.0 in stage 48.0 (TID 44)\n24/03/26 16:17:39 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:39 INFO CodeGenerator: Code generated in 42.025904 ms\n24/03/26 16:17:39 INFO CodeGenerator: Code generated in 14.848699 ms\n24/03/26 16:17:39 INFO CodeGenerator: Code generated in 11.485922 ms\n[Stage 48:>                                                         (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+-----+--------------------+\n|label|     features_scaled|\n+-----+--------------------+\n|  0.0|[5.19282199176603...|\n|  0.0|[5.31358529390013...|\n|  0.0|[5.31358529390013...|\n|  0.0|[5.31358529390013...|\n|  0.0|[5.43434859603422...|\n+-----+--------------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"24/03/26 16:17:40 INFO PythonRunner: Times: total = 1054, boot = 6, init = 1043, finish = 5\n24/03/26 16:17:40 INFO Executor: Finished task 0.0 in stage 48.0 (TID 44). 2930 bytes result sent to driver\n24/03/26 16:17:40 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 44) in 1114 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:40 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n24/03/26 16:17:40 INFO DAGScheduler: ResultStage 48 (showString at <unknown>:0) finished in 1.126 s\n24/03/26 16:17:40 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n24/03/26 16:17:40 INFO DAGScheduler: Job 39 finished: showString at <unknown>:0, took 1.130693 s\n                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"We will run a series of models,   this is the list of model names and storage for the results","metadata":{}},{"cell_type":"code","source":"model = ['Decision Tree','Random Forest','Naive Bayes']\nmodel_results = []","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:48.489374Z","iopub.execute_input":"2024-03-26T16:17:48.489853Z","iopub.status.idle":"2024-03-26T16:17:48.495521Z","shell.execute_reply.started":"2024-03-26T16:17:48.489818Z","shell.execute_reply":"2024-03-26T16:17:48.494184Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Build a descion tree classifier\n\nNote the interface style,  declare the model, setting parameters,  then train and then apply to the test data\n\nLooks kinda familiar at this point","metadata":{}},{"cell_type":"code","source":"# -- Decision Tree Classifier --\n\ndtc = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features_scaled\")          #instantiate the model\ndtc_model = dtc.fit(train_data)                                                        #train the model\ndtc_pred = dtc_model.transform(test_data)                                              #model predictions\n\n#Evaluate the Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndtc_acc = evaluator.evaluate(dtc_pred)\n#print(\"Decision Tree Classifier Accuracy =\", '{:.2%}'.format(dtc_acc))\nmodel_results.extend([[model[0],'{:.2%}'.format(dtc_acc)]])                               #appending to list","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:17:54.546761Z","iopub.execute_input":"2024-03-26T16:17:54.547163Z","iopub.status.idle":"2024-03-26T16:17:59.487724Z","shell.execute_reply.started":"2024-03-26T16:17:54.547134Z","shell.execute_reply":"2024-03-26T16:17:59.486266Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"24/03/26 16:17:54 INFO Instrumentation: [35215bcb] Stage class: DecisionTreeClassifier\n24/03/26 16:17:54 INFO Instrumentation: [35215bcb] Stage uid: DecisionTreeClassifier_1765d766a156\n24/03/26 16:17:54 INFO CodeGenerator: Code generated in 18.751542 ms\n24/03/26 16:17:54 INFO Instrumentation: [35215bcb] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n24/03/26 16:17:54 INFO CodeGenerator: Code generated in 26.085807 ms\n24/03/26 16:17:54 INFO DAGScheduler: Registering RDD 184 (take at DatasetUtils.scala:193) as input to shuffle 9\n24/03/26 16:17:54 INFO DAGScheduler: Got map stage job 40 (take at DatasetUtils.scala:193) with 1 output partitions\n24/03/26 16:17:54 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (take at DatasetUtils.scala:193)\n24/03/26 16:17:54 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:54 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:54 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[184] at take at DatasetUtils.scala:193), which has no missing parents\n24/03/26 16:17:54 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 82.4 KiB, free 433.1 MiB)\n24/03/26 16:17:54 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.1 MiB)\n24/03/26 16:17:54 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on b2edbf16b081:40551 (size: 36.4 KiB, free: 433.8 MiB)\n24/03/26 16:17:54 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[184] at take at DatasetUtils.scala:193) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:54 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n24/03/26 16:17:54 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:54 INFO Executor: Running task 0.0 in stage 49.0 (TID 45)\n24/03/26 16:17:54 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:54 INFO CodeGenerator: Code generated in 49.390758 ms\n24/03/26 16:17:55 INFO PythonRunner: Times: total = 279, boot = -14022, init = 14297, finish = 4\n24/03/26 16:17:55 INFO Executor: Finished task 0.0 in stage 49.0 (TID 45). 3257 bytes result sent to driver\n24/03/26 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 330 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n24/03/26 16:17:55 INFO DAGScheduler: ShuffleMapStage 49 (take at DatasetUtils.scala:193) finished in 0.344 s\n24/03/26 16:17:55 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:55 INFO DAGScheduler: running: Set()\n24/03/26 16:17:55 INFO DAGScheduler: waiting: Set()\n24/03/26 16:17:55 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 12.180627 ms\n24/03/26 16:17:55 INFO SparkContext: Starting job: take at DatasetUtils.scala:193\n24/03/26 16:17:55 INFO DAGScheduler: Got job 41 (take at DatasetUtils.scala:193) with 1 output partitions\n24/03/26 16:17:55 INFO DAGScheduler: Final stage: ResultStage 51 (take at DatasetUtils.scala:193)\n24/03/26 16:17:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)\n24/03/26 16:17:55 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:55 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[187] at take at DatasetUtils.scala:193), which has no missing parents\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 13.2 KiB, free 433.0 MiB)\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 433.0 MiB)\n24/03/26 16:17:55 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on b2edbf16b081:40551 (size: 6.2 KiB, free: 433.8 MiB)\n24/03/26 16:17:55 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[187] at take at DatasetUtils.scala:193) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n24/03/26 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:17:55 INFO Executor: Running task 0.0 in stage 51.0 (TID 46)\n24/03/26 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 12.933988 ms\n24/03/26 16:17:55 INFO Executor: Finished task 0.0 in stage 51.0 (TID 46). 3988 bytes result sent to driver\n24/03/26 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 25 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n24/03/26 16:17:55 INFO DAGScheduler: ResultStage 51 (take at DatasetUtils.scala:193) finished in 0.033 s\n24/03/26 16:17:55 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n24/03/26 16:17:55 INFO DAGScheduler: Job 41 finished: take at DatasetUtils.scala:193, took 0.037678 s\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 6.545328 ms\n24/03/26 16:17:55 INFO DatasetUtils: org.apache.spark.ml.util.DatasetUtils$ inferred 3 classes for labelCol=label since numClasses was not specified in the column metadata.\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 40.267902 ms\n24/03/26 16:17:55 INFO Instrumentation: [35215bcb] {\"numClasses\":3}\n24/03/26 16:17:55 INFO Instrumentation: [35215bcb] {\"labelCol\":\"label\",\"featuresCol\":\"features_scaled\"}\n24/03/26 16:17:55 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119\n24/03/26 16:17:55 INFO DAGScheduler: Got job 42 (take at DecisionTreeMetadata.scala:119) with 1 output partitions\n24/03/26 16:17:55 INFO DAGScheduler: Final stage: ResultStage 52 (take at DecisionTreeMetadata.scala:119)\n24/03/26 16:17:55 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:55 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:55 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[194] at map at DecisionTreeMetadata.scala:119), which has no missing parents\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 95.3 KiB, free 432.9 MiB)\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 39.6 KiB, free 432.9 MiB)\n24/03/26 16:17:55 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on b2edbf16b081:40551 (size: 39.6 KiB, free: 433.8 MiB)\n24/03/26 16:17:55 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[194] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n24/03/26 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:55 INFO Executor: Running task 0.0 in stage 52.0 (TID 47)\n24/03/26 16:17:55 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 47.7216 ms\n24/03/26 16:17:55 INFO CodeGenerator: Code generated in 7.470934 ms\n24/03/26 16:17:55 INFO PythonRunner: Times: total = 303, boot = -311, init = 610, finish = 4\n24/03/26 16:17:55 INFO Executor: Finished task 0.0 in stage 52.0 (TID 47). 2302 bytes result sent to driver\n24/03/26 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 355 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n24/03/26 16:17:55 INFO DAGScheduler: ResultStage 52 (take at DecisionTreeMetadata.scala:119) finished in 0.371 s\n24/03/26 16:17:55 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n24/03/26 16:17:55 INFO DAGScheduler: Job 42 finished: take at DecisionTreeMetadata.scala:119, took 0.375655 s\n24/03/26 16:17:55 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125\n24/03/26 16:17:55 INFO DAGScheduler: Got job 43 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions\n24/03/26 16:17:55 INFO DAGScheduler: Final stage: ResultStage 53 (aggregate at DecisionTreeMetadata.scala:125)\n24/03/26 16:17:55 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:17:55 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:17:55 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[193] at retag at RandomForest.scala:274), which has no missing parents\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 95.3 KiB, free 432.8 MiB)\n24/03/26 16:17:55 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 39.7 KiB, free 432.8 MiB)\n24/03/26 16:17:55 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on b2edbf16b081:40551 (size: 39.7 KiB, free: 433.7 MiB)\n24/03/26 16:17:55 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[193] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:55 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n24/03/26 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:17:55 INFO Executor: Running task 0.0 in stage 53.0 (TID 48)\n24/03/26 16:17:55 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:56 INFO PythonRunner: Times: total = 308, boot = -3, init = 305, finish = 6\n24/03/26 16:17:56 INFO Executor: Finished task 0.0 in stage 53.0 (TID 48). 2417 bytes result sent to driver\n24/03/26 16:17:56 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 356 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n24/03/26 16:17:56 INFO DAGScheduler: ResultStage 53 (aggregate at DecisionTreeMetadata.scala:125) finished in 0.366 s\n24/03/26 16:17:56 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n24/03/26 16:17:56 INFO DAGScheduler: Job 43 finished: aggregate at DecisionTreeMetadata.scala:125, took 0.370345 s\n24/03/26 16:17:56 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054\n24/03/26 16:17:56 INFO DAGScheduler: Registering RDD 196 (flatMap at RandomForest.scala:1039) as input to shuffle 10\n24/03/26 16:17:56 INFO DAGScheduler: Got job 44 (collectAsMap at RandomForest.scala:1054) with 1 output partitions\n24/03/26 16:17:56 INFO DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:1054)\n24/03/26 16:17:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n24/03/26 16:17:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n24/03/26 16:17:56 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[196] at flatMap at RandomForest.scala:1039), which has no missing parents\n24/03/26 16:17:56 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 99.5 KiB, free 432.7 MiB)\n24/03/26 16:17:56 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 41.6 KiB, free 432.6 MiB)\n24/03/26 16:17:56 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on b2edbf16b081:40551 (size: 41.6 KiB, free: 433.7 MiB)\n24/03/26 16:17:56 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[196] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:56 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n24/03/26 16:17:56 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 49) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:56 INFO Executor: Running task 0.0 in stage 54.0 (TID 49)\n24/03/26 16:17:56 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:56 INFO PythonRunner: Times: total = 342, boot = -206, init = 542, finish = 6\n24/03/26 16:17:56 INFO Executor: Finished task 0.0 in stage 54.0 (TID 49). 2510 bytes result sent to driver\n24/03/26 16:17:56 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 49) in 537 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n24/03/26 16:17:56 INFO DAGScheduler: ShuffleMapStage 54 (flatMap at RandomForest.scala:1039) finished in 0.548 s\n24/03/26 16:17:56 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:56 INFO DAGScheduler: running: Set()\n24/03/26 16:17:56 INFO DAGScheduler: waiting: Set(ResultStage 55)\n24/03/26 16:17:56 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:56 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[198] at map at RandomForest.scala:1054), which has no missing parents\n24/03/26 16:17:56 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 9.8 KiB, free 432.6 MiB)\n24/03/26 16:17:56 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 432.6 MiB)\n24/03/26 16:17:56 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on b2edbf16b081:40551 (size: 4.5 KiB, free: 433.7 MiB)\n24/03/26 16:17:56 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[198] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:56 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n24/03/26 16:17:56 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 50) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:56 INFO Executor: Running task 0.0 in stage 55.0 (TID 50)\n24/03/26 16:17:56 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:57 INFO Executor: Finished task 0.0 in stage 55.0 (TID 50). 4000 bytes result sent to driver\n24/03/26 16:17:57 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 50) in 56 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n24/03/26 16:17:57 INFO DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:1054) finished in 0.066 s\n24/03/26 16:17:57 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n24/03/26 16:17:57 INFO DAGScheduler: Job 44 finished: collectAsMap at RandomForest.scala:1054, took 0.626151 s\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 3.0 KiB, free 432.6 MiB)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 1250.0 B, free 432.6 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on b2edbf16b081:40551 (size: 1250.0 B, free: 433.7 MiB)\n24/03/26 16:17:57 INFO SparkContext: Created broadcast 52 from broadcast at RandomForest.scala:293\n24/03/26 16:17:57 INFO Instrumentation: [35215bcb] {\"numFeatures\":4}\n24/03/26 16:17:57 INFO Instrumentation: [35215bcb] {\"numClasses\":3}\n24/03/26 16:17:57 INFO Instrumentation: [35215bcb] {\"numExamples\":139}\n24/03/26 16:17:57 INFO Instrumentation: [35215bcb] {\"sumOfWeights\":139.0}\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 40.0 B, free 432.6 MiB)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 101.0 B, free 432.6 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on b2edbf16b081:40551 (size: 101.0 B, free: 433.7 MiB)\n24/03/26 16:17:57 INFO SparkContext: Created broadcast 53 from broadcast at RandomForest.scala:622\n24/03/26 16:17:57 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:17:57 INFO DAGScheduler: Registering RDD 201 (mapPartitions at RandomForest.scala:644) as input to shuffle 11\n24/03/26 16:17:57 INFO DAGScheduler: Got job 45 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:17:57 INFO DAGScheduler: Final stage: ResultStage 57 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:17:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)\n24/03/26 16:17:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)\n24/03/26 16:17:57 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[201] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 100.0 KiB, free 432.5 MiB)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 42.8 KiB, free 432.5 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on b2edbf16b081:40551 (size: 42.8 KiB, free: 433.7 MiB)\n24/03/26 16:17:57 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[201] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n24/03/26 16:17:57 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 51) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:57 INFO Executor: Running task 0.0 in stage 56.0 (TID 51)\n24/03/26 16:17:57 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:57 INFO PythonRunner: Times: total = 376, boot = -367, init = 737, finish = 6\n24/03/26 16:17:57 INFO MemoryStore: Block rdd_200_0 stored as values in memory (estimated size 13.6 KiB, free 432.5 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added rdd_200_0 in memory on b2edbf16b081:40551 (size: 13.6 KiB, free: 433.6 MiB)\n24/03/26 16:17:57 INFO Executor: Finished task 0.0 in stage 56.0 (TID 51). 2510 bytes result sent to driver\n24/03/26 16:17:57 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 51) in 516 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n24/03/26 16:17:57 INFO DAGScheduler: ShuffleMapStage 56 (mapPartitions at RandomForest.scala:644) finished in 0.548 s\n24/03/26 16:17:57 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:57 INFO DAGScheduler: running: Set()\n24/03/26 16:17:57 INFO DAGScheduler: waiting: Set(ResultStage 57)\n24/03/26 16:17:57 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:57 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[203] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 6.9 KiB, free 432.5 MiB)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.5 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on b2edbf16b081:40551 (size: 3.8 KiB, free: 433.6 MiB)\n24/03/26 16:17:57 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[203] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n24/03/26 16:17:57 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 52) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:57 INFO Executor: Running task 0.0 in stage 57.0 (TID 52)\n24/03/26 16:17:57 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n24/03/26 16:17:57 INFO Executor: Finished task 0.0 in stage 57.0 (TID 52). 2557 bytes result sent to driver\n24/03/26 16:17:57 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 52) in 234 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:57 INFO DAGScheduler: ResultStage 57 (collectAsMap at RandomForest.scala:663) finished in 0.246 s\n24/03/26 16:17:57 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:57 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n24/03/26 16:17:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n24/03/26 16:17:57 INFO DAGScheduler: Job 45 finished: collectAsMap at RandomForest.scala:663, took 0.807060 s\n24/03/26 16:17:57 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at RandomForest.scala:674)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 40.0 B, free 432.5 MiB)\n24/03/26 16:17:57 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 101.0 B, free 432.5 MiB)\n24/03/26 16:17:57 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on b2edbf16b081:40551 (size: 101.0 B, free: 433.6 MiB)\n24/03/26 16:17:57 INFO SparkContext: Created broadcast 56 from broadcast at RandomForest.scala:622\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_53_piece0 on b2edbf16b081:40551 in memory (size: 101.0 B, free: 433.6 MiB)\n24/03/26 16:17:58 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:17:58 INFO DAGScheduler: Registering RDD 204 (mapPartitions at RandomForest.scala:644) as input to shuffle 12\n24/03/26 16:17:58 INFO DAGScheduler: Got job 46 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:17:58 INFO DAGScheduler: Final stage: ResultStage 59 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)\n24/03/26 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[204] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 100.8 KiB, free 432.4 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 43.2 KiB, free 432.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on b2edbf16b081:40551 (size: 43.2 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[204] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 53) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 58.0 (TID 53)\n24/03/26 16:17:58 INFO BlockManager: Found block rdd_200_0 locally\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 58.0 (TID 53). 2553 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 53) in 26 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ShuffleMapStage 58 (mapPartitions at RandomForest.scala:644) finished in 0.043 s\n24/03/26 16:17:58 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:58 INFO DAGScheduler: running: Set()\n24/03/26 16:17:58 INFO DAGScheduler: waiting: Set(ResultStage 59)\n24/03/26 16:17:58 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[206] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 7.4 KiB, free 432.3 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 432.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on b2edbf16b081:40551 (size: 4.0 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[206] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 54) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 59.0 (TID 54)\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 (2.2 KiB) non-empty blocks including 1 (2.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 59.0 (TID 54). 2557 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 54) in 19 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ResultStage 59 (collectAsMap at RandomForest.scala:663) finished in 0.025 s\n24/03/26 16:17:58 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n24/03/26 16:17:58 INFO DAGScheduler: Job 46 finished: collectAsMap at RandomForest.scala:663, took 0.079849 s\n24/03/26 16:17:58 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at RandomForest.scala:674)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 40.0 B, free 432.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_56_piece0 on b2edbf16b081:40551 in memory (size: 101.0 B, free: 433.6 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 101.0 B, free 432.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on b2edbf16b081:40551 (size: 101.0 B, free: 433.6 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 59 from broadcast at RandomForest.scala:622\n24/03/26 16:17:58 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:17:58 INFO DAGScheduler: Registering RDD 207 (mapPartitions at RandomForest.scala:644) as input to shuffle 13\n24/03/26 16:17:58 INFO DAGScheduler: Got job 47 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:17:58 INFO DAGScheduler: Final stage: ResultStage 61 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)\n24/03/26 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[207] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 101.2 KiB, free 432.2 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 43.4 KiB, free 432.2 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on b2edbf16b081:40551 (size: 43.4 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[207] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 55) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 60.0 (TID 55)\n24/03/26 16:17:58 INFO BlockManager: Found block rdd_200_0 locally\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 60.0 (TID 55). 2510 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 55) in 22 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ShuffleMapStage 60 (mapPartitions at RandomForest.scala:644) finished in 0.035 s\n24/03/26 16:17:58 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:58 INFO DAGScheduler: running: Set()\n24/03/26 16:17:58 INFO DAGScheduler: waiting: Set(ResultStage 61)\n24/03/26 16:17:58 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[209] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.5 KiB, free 432.2 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 432.1 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on b2edbf16b081:40551 (size: 4.0 KiB, free: 433.5 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[209] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 56) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 61.0 (TID 56)\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 (2.4 KiB) non-empty blocks including 1 (2.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 61.0 (TID 56). 2723 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 56) in 19 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ResultStage 61 (collectAsMap at RandomForest.scala:663) finished in 0.026 s\n24/03/26 16:17:58 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n24/03/26 16:17:58 INFO DAGScheduler: Job 47 finished: collectAsMap at RandomForest.scala:663, took 0.071045 s\n24/03/26 16:17:58 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at RandomForest.scala:674)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 40.0 B, free 432.1 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_59_piece0 on b2edbf16b081:40551 in memory (size: 101.0 B, free: 433.5 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 101.0 B, free 432.1 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on b2edbf16b081:40551 (size: 101.0 B, free: 433.5 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 62 from broadcast at RandomForest.scala:622\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_44_piece0 on b2edbf16b081:40551 in memory (size: 26.3 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_61_piece0 on b2edbf16b081:40551 in memory (size: 4.0 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_45_piece0 on b2edbf16b081:40551 in memory (size: 31.0 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_55_piece0 on b2edbf16b081:40551 in memory (size: 3.8 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_46_piece0 on b2edbf16b081:40551 in memory (size: 36.4 KiB, free: 433.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_43_piece0 on b2edbf16b081:40551 in memory (size: 30.7 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_50_piece0 on b2edbf16b081:40551 in memory (size: 41.6 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO DAGScheduler: Registering RDD 210 (mapPartitions at RandomForest.scala:644) as input to shuffle 14\n24/03/26 16:17:58 INFO DAGScheduler: Got job 48 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:17:58 INFO DAGScheduler: Final stage: ResultStage 63 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)\n24/03/26 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[210] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 101.6 KiB, free 432.6 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 432.6 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on b2edbf16b081:40551 (size: 43.5 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[210] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_49_piece0 on b2edbf16b081:40551 in memory (size: 39.7 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 57) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 62.0 (TID 57)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_42_piece0 on b2edbf16b081:40551 in memory (size: 27.8 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO BlockManager: Found block rdd_200_0 locally\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 62.0 (TID 57). 2510 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 57) in 21 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ShuffleMapStage 62 (mapPartitions at RandomForest.scala:644) finished in 0.039 s\n24/03/26 16:17:58 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:58 INFO DAGScheduler: running: Set()\n24/03/26 16:17:58 INFO DAGScheduler: waiting: Set(ResultStage 63)\n24/03/26 16:17:58 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[212] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 7.6 KiB, free 432.8 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 432.8 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on b2edbf16b081:40551 (size: 4.1 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[212] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_51_piece0 on b2edbf16b081:40551 in memory (size: 4.5 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 58) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 63.0 (TID 58)\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 (2.2 KiB) non-empty blocks including 1 (2.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 63.0 (TID 58). 2930 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 58) in 17 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ResultStage 63 (collectAsMap at RandomForest.scala:663) finished in 0.024 s\n24/03/26 16:17:58 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n24/03/26 16:17:58 INFO DAGScheduler: Job 48 finished: collectAsMap at RandomForest.scala:663, took 0.068966 s\n24/03/26 16:17:58 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at RandomForest.scala:674)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 40.0 B, free 432.8 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 101.0 B, free 432.8 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on b2edbf16b081:40551 (size: 101.0 B, free: 433.7 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 65 from broadcast at RandomForest.scala:622\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_62_piece0 on b2edbf16b081:40551 in memory (size: 101.0 B, free: 433.7 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_47_piece0 on b2edbf16b081:40551 in memory (size: 6.2 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_58_piece0 on b2edbf16b081:40551 in memory (size: 4.0 KiB, free: 433.7 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_60_piece0 on b2edbf16b081:40551 in memory (size: 43.4 KiB, free: 433.8 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_54_piece0 on b2edbf16b081:40551 in memory (size: 42.8 KiB, free: 433.8 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_48_piece0 on b2edbf16b081:40551 in memory (size: 39.6 KiB, free: 433.9 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_41_piece0 on b2edbf16b081:40551 in memory (size: 24.4 KiB, free: 433.9 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_57_piece0 on b2edbf16b081:40551 in memory (size: 43.2 KiB, free: 433.9 MiB)\n24/03/26 16:17:58 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:17:58 INFO DAGScheduler: Registering RDD 213 (mapPartitions at RandomForest.scala:644) as input to shuffle 15\n24/03/26 16:17:58 INFO DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:17:58 INFO DAGScheduler: Final stage: ResultStage 65 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)\n24/03/26 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[213] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 102.4 KiB, free 433.3 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 43.7 KiB, free 433.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on b2edbf16b081:40551 (size: 43.7 KiB, free: 433.9 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[213] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 59) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 64.0 (TID 59)\n24/03/26 16:17:58 INFO BlockManager: Found block rdd_200_0 locally\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 64.0 (TID 59). 2510 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 59) in 18 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ShuffleMapStage 64 (mapPartitions at RandomForest.scala:644) finished in 0.029 s\n24/03/26 16:17:58 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:58 INFO DAGScheduler: running: Set()\n24/03/26 16:17:58 INFO DAGScheduler: waiting: Set(ResultStage 65)\n24/03/26 16:17:58 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:58 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[215] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 7.4 KiB, free 433.3 MiB)\n24/03/26 16:17:58 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 433.3 MiB)\n24/03/26 16:17:58 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on b2edbf16b081:40551 (size: 4.0 KiB, free: 433.9 MiB)\n24/03/26 16:17:58 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[215] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n24/03/26 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 60) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:58 INFO Executor: Running task 0.0 in stage 65.0 (TID 60)\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 (1692.0 B) non-empty blocks including 1 (1692.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:58 INFO Executor: Finished task 0.0 in stage 65.0 (TID 60). 2514 bytes result sent to driver\n24/03/26 16:17:58 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 60) in 10 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n24/03/26 16:17:58 INFO DAGScheduler: ResultStage 65 (collectAsMap at RandomForest.scala:663) finished in 0.017 s\n24/03/26 16:17:58 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n24/03/26 16:17:58 INFO DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:663, took 0.051778 s\n24/03/26 16:17:58 INFO TorrentBroadcast: Destroying Broadcast(65) (from destroy at RandomForest.scala:674)\n24/03/26 16:17:58 INFO RandomForest: Internal timing for DecisionTree:\n24/03/26 16:17:58 INFO RandomForest:   init: 0.004203948\n  total: 1.656422743\n  findBestSplits: 1.643229295\n  chooseSplits: 1.633878624\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_65_piece0 on b2edbf16b081:40551 in memory (size: 101.0 B, free: 433.9 MiB)\n24/03/26 16:17:58 INFO MapPartitionsRDD: Removing RDD 200 from persistence list\n24/03/26 16:17:58 INFO BlockManager: Removing RDD 200\n24/03/26 16:17:58 INFO TorrentBroadcast: Destroying Broadcast(52) (from destroy at RandomForest.scala:305)\n24/03/26 16:17:58 INFO Instrumentation: [35215bcb] training finished\n24/03/26 16:17:58 INFO BlockManagerInfo: Removed broadcast_52_piece0 on b2edbf16b081:40551 in memory (size: 1250.0 B, free: 433.9 MiB)\n24/03/26 16:17:58 INFO CodeGenerator: Code generated in 25.982313 ms\n24/03/26 16:17:59 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61\n24/03/26 16:17:59 INFO DAGScheduler: Registering RDD 221 (map at MulticlassMetrics.scala:52) as input to shuffle 16\n24/03/26 16:17:59 INFO DAGScheduler: Got job 50 (collectAsMap at MulticlassMetrics.scala:61) with 1 output partitions\n24/03/26 16:17:59 INFO DAGScheduler: Final stage: ResultStage 67 (collectAsMap at MulticlassMetrics.scala:61)\n24/03/26 16:17:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n24/03/26 16:17:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)\n24/03/26 16:17:59 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[221] at map at MulticlassMetrics.scala:52), which has no missing parents\n24/03/26 16:17:59 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 100.1 KiB, free 433.2 MiB)\n24/03/26 16:17:59 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 41.5 KiB, free 433.2 MiB)\n24/03/26 16:17:59 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on b2edbf16b081:40551 (size: 41.5 KiB, free: 433.9 MiB)\n24/03/26 16:17:59 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[221] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:59 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n24/03/26 16:17:59 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 61) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:17:59 INFO Executor: Running task 0.0 in stage 66.0 (TID 61)\n24/03/26 16:17:59 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:17:59 INFO CodeGenerator: Code generated in 42.460213 ms\n24/03/26 16:17:59 INFO CodeGenerator: Code generated in 8.381154 ms\n24/03/26 16:17:59 INFO PythonRunner: Times: total = 265, boot = -1419, init = 1680, finish = 4\n24/03/26 16:17:59 INFO Executor: Finished task 0.0 in stage 66.0 (TID 61). 2510 bytes result sent to driver\n24/03/26 16:17:59 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 61) in 342 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:59 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n24/03/26 16:17:59 INFO DAGScheduler: ShuffleMapStage 66 (map at MulticlassMetrics.scala:52) finished in 0.361 s\n24/03/26 16:17:59 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:17:59 INFO DAGScheduler: running: Set()\n24/03/26 16:17:59 INFO DAGScheduler: waiting: Set(ResultStage 67)\n24/03/26 16:17:59 INFO DAGScheduler: failed: Set()\n24/03/26 16:17:59 INFO DAGScheduler: Submitting ResultStage 67 (ShuffledRDD[222] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents\n24/03/26 16:17:59 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.7 KiB, free 433.2 MiB)\n24/03/26 16:17:59 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 433.2 MiB)\n24/03/26 16:17:59 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on b2edbf16b081:40551 (size: 2.8 KiB, free: 433.9 MiB)\n24/03/26 16:17:59 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:17:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (ShuffledRDD[222] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:17:59 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n24/03/26 16:17:59 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 62) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:17:59 INFO Executor: Running task 0.0 in stage 67.0 (TID 62)\n24/03/26 16:17:59 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:17:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:17:59 INFO Executor: Finished task 0.0 in stage 67.0 (TID 62). 2068 bytes result sent to driver\n24/03/26 16:17:59 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 62) in 14 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:17:59 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n24/03/26 16:17:59 INFO DAGScheduler: ResultStage 67 (collectAsMap at MulticlassMetrics.scala:61) finished in 0.025 s\n24/03/26 16:17:59 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:17:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n24/03/26 16:17:59 INFO DAGScheduler: Job 50 finished: collectAsMap at MulticlassMetrics.scala:61, took 0.392480 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here's a random forest.\n\nOnly 10 trees?  Just saving time I suppose, the IRIS set is easy","metadata":{}},{"cell_type":"code","source":"# -- Random Forest Classifier --\n\nrfc = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_scaled\", numTrees=10)          #instantiate the model\nrfc_model = rfc.fit(train_data)                                                                     #train the model\nrfc_pred = rfc_model.transform(test_data)                                                           #model predictions\n\n#Evaluate the Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrfc_acc = evaluator.evaluate(rfc_pred)\n#print(\"Random Forest Classifier Accuracy =\", '{:.2%}'.format(rfc_acc))\nmodel_results.extend([[model[1],'{:.2%}'.format(rfc_acc)]])                                            #appending to list","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:18:10.230049Z","iopub.execute_input":"2024-03-26T16:18:10.230429Z","iopub.status.idle":"2024-03-26T16:18:13.898190Z","shell.execute_reply.started":"2024-03-26T16:18:10.230401Z","shell.execute_reply":"2024-03-26T16:18:13.896376Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"24/03/26 16:18:10 INFO Instrumentation: [36166e1c] Stage class: RandomForestClassifier\n24/03/26 16:18:10 INFO Instrumentation: [36166e1c] Stage uid: RandomForestClassifier_8849dfebca3c\n24/03/26 16:18:10 INFO Instrumentation: [36166e1c] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n24/03/26 16:18:10 INFO DAGScheduler: Registering RDD 228 (take at DatasetUtils.scala:193) as input to shuffle 17\n24/03/26 16:18:10 INFO DAGScheduler: Got map stage job 51 (take at DatasetUtils.scala:193) with 1 output partitions\n24/03/26 16:18:10 INFO DAGScheduler: Final stage: ShuffleMapStage 68 (take at DatasetUtils.scala:193)\n24/03/26 16:18:10 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:18:10 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:10 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[228] at take at DatasetUtils.scala:193), which has no missing parents\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 82.4 KiB, free 433.1 MiB)\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.0 MiB)\n24/03/26 16:18:10 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on b2edbf16b081:40551 (size: 36.4 KiB, free: 433.8 MiB)\n24/03/26 16:18:10 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[228] at take at DatasetUtils.scala:193) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n24/03/26 16:18:10 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 63) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:10 INFO Executor: Running task 0.0 in stage 68.0 (TID 63)\n24/03/26 16:18:10 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:10 INFO PythonRunner: Times: total = 271, boot = -10977, init = 11244, finish = 4\n24/03/26 16:18:10 INFO Executor: Finished task 0.0 in stage 68.0 (TID 63). 3257 bytes result sent to driver\n24/03/26 16:18:10 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 63) in 302 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n24/03/26 16:18:10 INFO DAGScheduler: ShuffleMapStage 68 (take at DatasetUtils.scala:193) finished in 0.312 s\n24/03/26 16:18:10 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:10 INFO DAGScheduler: running: Set()\n24/03/26 16:18:10 INFO DAGScheduler: waiting: Set()\n24/03/26 16:18:10 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:10 INFO SparkContext: Starting job: take at DatasetUtils.scala:193\n24/03/26 16:18:10 INFO DAGScheduler: Got job 52 (take at DatasetUtils.scala:193) with 1 output partitions\n24/03/26 16:18:10 INFO DAGScheduler: Final stage: ResultStage 70 (take at DatasetUtils.scala:193)\n24/03/26 16:18:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)\n24/03/26 16:18:10 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:10 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[231] at take at DatasetUtils.scala:193), which has no missing parents\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 13.2 KiB, free 433.0 MiB)\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 433.0 MiB)\n24/03/26 16:18:10 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on b2edbf16b081:40551 (size: 6.2 KiB, free: 433.8 MiB)\n24/03/26 16:18:10 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[231] at take at DatasetUtils.scala:193) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n24/03/26 16:18:10 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 64) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:18:10 INFO Executor: Running task 0.0 in stage 70.0 (TID 64)\n24/03/26 16:18:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n24/03/26 16:18:10 INFO Executor: Finished task 0.0 in stage 70.0 (TID 64). 3988 bytes result sent to driver\n24/03/26 16:18:10 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 64) in 10 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n24/03/26 16:18:10 INFO DAGScheduler: ResultStage 70 (take at DatasetUtils.scala:193) finished in 0.031 s\n24/03/26 16:18:10 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished\n24/03/26 16:18:10 INFO DAGScheduler: Job 52 finished: take at DatasetUtils.scala:193, took 0.042242 s\n24/03/26 16:18:10 INFO DatasetUtils: org.apache.spark.ml.util.DatasetUtils$ inferred 3 classes for labelCol=label since numClasses was not specified in the column metadata.\n24/03/26 16:18:10 INFO Instrumentation: [36166e1c] {\"labelCol\":\"label\",\"featuresCol\":\"features_scaled\",\"numTrees\":10}\n24/03/26 16:18:10 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119\n24/03/26 16:18:10 INFO DAGScheduler: Got job 53 (take at DecisionTreeMetadata.scala:119) with 1 output partitions\n24/03/26 16:18:10 INFO DAGScheduler: Final stage: ResultStage 71 (take at DecisionTreeMetadata.scala:119)\n24/03/26 16:18:10 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:18:10 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:10 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[238] at map at DecisionTreeMetadata.scala:119), which has no missing parents\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 95.4 KiB, free 432.9 MiB)\n24/03/26 16:18:10 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 39.7 KiB, free 432.9 MiB)\n24/03/26 16:18:10 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on b2edbf16b081:40551 (size: 39.7 KiB, free: 433.8 MiB)\n24/03/26 16:18:10 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[238] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:10 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n24/03/26 16:18:10 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 65) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:18:10 INFO Executor: Running task 0.0 in stage 71.0 (TID 65)\n24/03/26 16:18:11 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:11 INFO PythonRunner: Times: total = 299, boot = -229, init = 522, finish = 6\n24/03/26 16:18:11 INFO Executor: Finished task 0.0 in stage 71.0 (TID 65). 2302 bytes result sent to driver\n24/03/26 16:18:11 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 65) in 331 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n24/03/26 16:18:11 INFO DAGScheduler: ResultStage 71 (take at DecisionTreeMetadata.scala:119) finished in 0.342 s\n24/03/26 16:18:11 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n24/03/26 16:18:11 INFO DAGScheduler: Job 53 finished: take at DecisionTreeMetadata.scala:119, took 0.347121 s\n24/03/26 16:18:11 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125\n24/03/26 16:18:11 INFO DAGScheduler: Got job 54 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions\n24/03/26 16:18:11 INFO DAGScheduler: Final stage: ResultStage 72 (aggregate at DecisionTreeMetadata.scala:125)\n24/03/26 16:18:11 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:18:11 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:11 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[237] at retag at RandomForest.scala:274), which has no missing parents\n24/03/26 16:18:11 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 95.4 KiB, free 432.8 MiB)\n24/03/26 16:18:11 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 39.8 KiB, free 432.8 MiB)\n24/03/26 16:18:11 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on b2edbf16b081:40551 (size: 39.8 KiB, free: 433.7 MiB)\n24/03/26 16:18:11 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[237] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n24/03/26 16:18:11 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 66) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8212 bytes) \n24/03/26 16:18:11 INFO Executor: Running task 0.0 in stage 72.0 (TID 66)\n24/03/26 16:18:11 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:11 INFO PythonRunner: Times: total = 329, boot = -5, init = 330, finish = 4\n24/03/26 16:18:11 INFO Executor: Finished task 0.0 in stage 72.0 (TID 66). 2417 bytes result sent to driver\n24/03/26 16:18:11 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 66) in 369 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n24/03/26 16:18:11 INFO DAGScheduler: ResultStage 72 (aggregate at DecisionTreeMetadata.scala:125) finished in 0.382 s\n24/03/26 16:18:11 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished\n24/03/26 16:18:11 INFO DAGScheduler: Job 54 finished: aggregate at DecisionTreeMetadata.scala:125, took 0.387673 s\n24/03/26 16:18:11 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054\n24/03/26 16:18:11 INFO DAGScheduler: Registering RDD 240 (flatMap at RandomForest.scala:1039) as input to shuffle 18\n24/03/26 16:18:11 INFO DAGScheduler: Got job 55 (collectAsMap at RandomForest.scala:1054) with 1 output partitions\n24/03/26 16:18:11 INFO DAGScheduler: Final stage: ResultStage 74 (collectAsMap at RandomForest.scala:1054)\n24/03/26 16:18:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)\n24/03/26 16:18:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)\n24/03/26 16:18:11 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[240] at flatMap at RandomForest.scala:1039), which has no missing parents\n24/03/26 16:18:11 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 99.6 KiB, free 432.7 MiB)\n24/03/26 16:18:11 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 41.6 KiB, free 432.6 MiB)\n24/03/26 16:18:11 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on b2edbf16b081:40551 (size: 41.6 KiB, free: 433.7 MiB)\n24/03/26 16:18:11 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[240] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:11 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0\n24/03/26 16:18:11 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 67) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:11 INFO Executor: Running task 0.0 in stage 73.0 (TID 67)\n24/03/26 16:18:11 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:12 INFO PythonRunner: Times: total = 265, boot = -25, init = 286, finish = 4\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 73.0 (TID 67). 2510 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 67) in 318 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ShuffleMapStage 73 (flatMap at RandomForest.scala:1039) finished in 0.330 s\n24/03/26 16:18:12 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:12 INFO DAGScheduler: running: Set()\n24/03/26 16:18:12 INFO DAGScheduler: waiting: Set(ResultStage 74)\n24/03/26 16:18:12 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[242] at map at RandomForest.scala:1054), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 9.8 KiB, free 432.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 432.6 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on b2edbf16b081:40551 (size: 4.5 KiB, free: 433.7 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[242] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 68) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 74.0 (TID 68)\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 74.0 (TID 68). 3957 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 68) in 13 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ResultStage 74 (collectAsMap at RandomForest.scala:1054) finished in 0.022 s\n24/03/26 16:18:12 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n24/03/26 16:18:12 INFO DAGScheduler: Job 55 finished: collectAsMap at RandomForest.scala:1054, took 0.361029 s\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 3.0 KiB, free 432.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1250.0 B, free 432.6 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on b2edbf16b081:40551 (size: 1250.0 B, free: 433.7 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 76 from broadcast at RandomForest.scala:293\n24/03/26 16:18:12 INFO Instrumentation: [36166e1c] {\"numFeatures\":4}\n24/03/26 16:18:12 INFO Instrumentation: [36166e1c] {\"numClasses\":3}\n24/03/26 16:18:12 INFO Instrumentation: [36166e1c] {\"numExamples\":139}\n24/03/26 16:18:12 INFO Instrumentation: [36166e1c] {\"sumOfWeights\":139.0}\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 1080.0 B, free 432.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 384.0 B, free 432.6 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on b2edbf16b081:40551 (size: 384.0 B, free: 433.7 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 77 from broadcast at RandomForest.scala:622\n24/03/26 16:18:12 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:18:12 INFO DAGScheduler: Registering RDD 245 (mapPartitions at RandomForest.scala:644) as input to shuffle 19\n24/03/26 16:18:12 INFO DAGScheduler: Got job 56 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:18:12 INFO DAGScheduler: Final stage: ResultStage 76 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:18:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\n24/03/26 16:18:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[245] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 100.9 KiB, free 432.5 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 43.2 KiB, free 432.5 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on b2edbf16b081:40551 (size: 43.2 KiB, free: 433.7 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[245] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 69) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 75.0 (TID 69)\n24/03/26 16:18:12 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:12 INFO PythonRunner: Times: total = 252, boot = -64, init = 311, finish = 5\n24/03/26 16:18:12 INFO MemoryStore: Block rdd_244_0 stored as values in memory (estimated size 21.2 KiB, free 432.4 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added rdd_244_0 in memory on b2edbf16b081:40551 (size: 21.2 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 75.0 (TID 69). 2510 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 69) in 317 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at RandomForest.scala:644) finished in 0.330 s\n24/03/26 16:18:12 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:12 INFO DAGScheduler: running: Set()\n24/03/26 16:18:12 INFO DAGScheduler: waiting: Set(ResultStage 76)\n24/03/26 16:18:12 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[247] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 7.2 KiB, free 432.4 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.4 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on b2edbf16b081:40551 (size: 3.8 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[247] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 70) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 76.0 (TID 70)\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Getting 1 (6.9 KiB) non-empty blocks including 1 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 76.0 (TID 70). 4309 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 70) in 16 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ResultStage 76 (collectAsMap at RandomForest.scala:663) finished in 0.025 s\n24/03/26 16:18:12 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n24/03/26 16:18:12 INFO DAGScheduler: Job 56 finished: collectAsMap at RandomForest.scala:663, took 0.367339 s\n24/03/26 16:18:12 INFO TorrentBroadcast: Destroying Broadcast(77) (from destroy at RandomForest.scala:674)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_77_piece0 on b2edbf16b081:40551 in memory (size: 384.0 B, free: 433.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 1184.0 B, free 432.4 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 377.0 B, free 432.4 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on b2edbf16b081:40551 (size: 377.0 B, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 80 from broadcast at RandomForest.scala:622\n24/03/26 16:18:12 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:18:12 INFO DAGScheduler: Registering RDD 248 (mapPartitions at RandomForest.scala:644) as input to shuffle 20\n24/03/26 16:18:12 INFO DAGScheduler: Got job 57 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:18:12 INFO DAGScheduler: Final stage: ResultStage 78 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:18:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)\n24/03/26 16:18:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 77)\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[248] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 104.4 KiB, free 432.3 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 44.4 KiB, free 432.3 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on b2edbf16b081:40551 (size: 44.4 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[248] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 71) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 77.0 (TID 71)\n24/03/26 16:18:12 INFO BlockManager: Found block rdd_244_0 locally\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 77.0 (TID 71). 2510 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 71) in 25 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at RandomForest.scala:644) finished in 0.038 s\n24/03/26 16:18:12 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:12 INFO DAGScheduler: running: Set()\n24/03/26 16:18:12 INFO DAGScheduler: waiting: Set(ResultStage 78)\n24/03/26 16:18:12 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[250] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.3 KiB, free 432.3 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 432.3 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on b2edbf16b081:40551 (size: 4.3 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[250] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 72) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 78.0 (TID 72)\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Getting 1 (5.7 KiB) non-empty blocks including 1 (5.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 78.0 (TID 72). 4542 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 72) in 18 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ResultStage 78 (collectAsMap at RandomForest.scala:663) finished in 0.025 s\n24/03/26 16:18:12 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n24/03/26 16:18:12 INFO DAGScheduler: Job 57 finished: collectAsMap at RandomForest.scala:663, took 0.070707 s\n24/03/26 16:18:12 INFO TorrentBroadcast: Destroying Broadcast(80) (from destroy at RandomForest.scala:674)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 2.0 KiB, free 432.3 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_80_piece0 on b2edbf16b081:40551 in memory (size: 377.0 B, free: 433.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 453.0 B, free 432.3 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on b2edbf16b081:40551 (size: 453.0 B, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 83 from broadcast at RandomForest.scala:622\n24/03/26 16:18:12 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:18:12 INFO DAGScheduler: Registering RDD 251 (mapPartitions at RandomForest.scala:644) as input to shuffle 21\n24/03/26 16:18:12 INFO DAGScheduler: Got job 58 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:18:12 INFO DAGScheduler: Final stage: ResultStage 80 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:18:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n24/03/26 16:18:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[251] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 107.6 KiB, free 432.2 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 45.5 KiB, free 432.1 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on b2edbf16b081:40551 (size: 45.5 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[251] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 73) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 79.0 (TID 73)\n24/03/26 16:18:12 INFO BlockManager: Found block rdd_244_0 locally\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 79.0 (TID 73). 2510 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 73) in 21 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at RandomForest.scala:644) finished in 0.033 s\n24/03/26 16:18:12 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:12 INFO DAGScheduler: running: Set()\n24/03/26 16:18:12 INFO DAGScheduler: waiting: Set(ResultStage 80)\n24/03/26 16:18:12 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[253] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 9.2 KiB, free 432.1 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 432.1 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on b2edbf16b081:40551 (size: 4.5 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[253] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 74) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 80.0 (TID 74)\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Getting 1 (6.9 KiB) non-empty blocks including 1 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 80.0 (TID 74). 6389 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 74) in 20 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ResultStage 80 (collectAsMap at RandomForest.scala:663) finished in 0.026 s\n24/03/26 16:18:12 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n24/03/26 16:18:12 INFO DAGScheduler: Job 58 finished: collectAsMap at RandomForest.scala:663, took 0.066930 s\n24/03/26 16:18:12 INFO TorrentBroadcast: Destroying Broadcast(83) (from destroy at RandomForest.scala:674)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_83_piece0 on b2edbf16b081:40551 in memory (size: 453.0 B, free: 433.5 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 1784.0 B, free 432.1 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 438.0 B, free 432.1 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on b2edbf16b081:40551 (size: 438.0 B, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 86 from broadcast at RandomForest.scala:622\n24/03/26 16:18:12 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:18:12 INFO DAGScheduler: Registering RDD 254 (mapPartitions at RandomForest.scala:644) as input to shuffle 22\n24/03/26 16:18:12 INFO DAGScheduler: Got job 59 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:18:12 INFO DAGScheduler: Final stage: ResultStage 82 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:18:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\n24/03/26 16:18:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[254] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 112.6 KiB, free 432.0 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 432.0 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on b2edbf16b081:40551 (size: 46.9 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[254] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 75) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 81.0 (TID 75)\n24/03/26 16:18:12 INFO BlockManager: Found block rdd_244_0 locally\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 81.0 (TID 75). 2510 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 75) in 21 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ShuffleMapStage 81 (mapPartitions at RandomForest.scala:644) finished in 0.030 s\n24/03/26 16:18:12 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:12 INFO DAGScheduler: running: Set()\n24/03/26 16:18:12 INFO DAGScheduler: waiting: Set(ResultStage 82)\n24/03/26 16:18:12 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[256] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 8.9 KiB, free 431.9 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 431.9 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on b2edbf16b081:40551 (size: 4.4 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[256] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n24/03/26 16:18:12 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 76) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:12 INFO Executor: Running task 0.0 in stage 82.0 (TID 76)\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Getting 1 (4.7 KiB) non-empty blocks including 1 (4.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_71_piece0 on b2edbf16b081:40551 in memory (size: 6.2 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_75_piece0 on b2edbf16b081:40551 in memory (size: 4.5 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_63_piece0 on b2edbf16b081:40551 in memory (size: 43.5 KiB, free: 433.5 MiB)\n24/03/26 16:18:12 INFO Executor: Finished task 0.0 in stage 82.0 (TID 76). 5806 bytes result sent to driver\n24/03/26 16:18:12 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 76) in 57 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n24/03/26 16:18:12 INFO DAGScheduler: ResultStage 82 (collectAsMap at RandomForest.scala:663) finished in 0.102 s\n24/03/26 16:18:12 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished\n24/03/26 16:18:12 INFO DAGScheduler: Job 59 finished: collectAsMap at RandomForest.scala:663, took 0.139788 s\n24/03/26 16:18:12 INFO TorrentBroadcast: Destroying Broadcast(86) (from destroy at RandomForest.scala:674)\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_86_piece0 on b2edbf16b081:40551 in memory (size: 438.0 B, free: 433.5 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 984.0 B, free 432.1 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 360.0 B, free 432.1 MiB)\n24/03/26 16:18:12 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on b2edbf16b081:40551 (size: 360.0 B, free: 433.5 MiB)\n24/03/26 16:18:12 INFO SparkContext: Created broadcast 89 from broadcast at RandomForest.scala:622\n24/03/26 16:18:12 INFO BlockManager: Removing RDD 200\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_72_piece0 on b2edbf16b081:40551 in memory (size: 39.7 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_82_piece0 on b2edbf16b081:40551 in memory (size: 4.3 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO DAGScheduler: Registering RDD 257 (mapPartitions at RandomForest.scala:644) as input to shuffle 23\n24/03/26 16:18:12 INFO DAGScheduler: Got job 60 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n24/03/26 16:18:12 INFO DAGScheduler: Final stage: ResultStage 84 (collectAsMap at RandomForest.scala:663)\n24/03/26 16:18:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)\n24/03/26 16:18:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)\n24/03/26 16:18:12 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[257] at mapPartitions at RandomForest.scala:644), which has no missing parents\n24/03/26 16:18:12 INFO BlockManagerInfo: Removed broadcast_81_piece0 on b2edbf16b081:40551 in memory (size: 44.4 KiB, free: 433.6 MiB)\n24/03/26 16:18:12 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 113.8 KiB, free 432.2 MiB)\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 47.1 KiB, free 432.2 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on b2edbf16b081:40551 (size: 47.1 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_85_piece0 on b2edbf16b081:40551 in memory (size: 4.5 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[257] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n24/03/26 16:18:13 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 77) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_79_piece0 on b2edbf16b081:40551 in memory (size: 3.8 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO Executor: Running task 0.0 in stage 83.0 (TID 77)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_68_piece0 on b2edbf16b081:40551 in memory (size: 41.5 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO BlockManager: Found block rdd_244_0 locally\n24/03/26 16:18:13 INFO Executor: Finished task 0.0 in stage 83.0 (TID 77). 2510 bytes result sent to driver\n24/03/26 16:18:13 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 77) in 34 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n24/03/26 16:18:13 INFO DAGScheduler: ShuffleMapStage 83 (mapPartitions at RandomForest.scala:644) finished in 0.095 s\n24/03/26 16:18:13 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:13 INFO DAGScheduler: running: Set()\n24/03/26 16:18:13 INFO DAGScheduler: waiting: Set(ResultStage 84)\n24/03/26 16:18:13 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:13 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[259] at map at RandomForest.scala:663), which has no missing parents\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 8.1 KiB, free 432.4 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_64_piece0 on b2edbf16b081:40551 in memory (size: 4.1 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 432.4 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on b2edbf16b081:40551 (size: 4.2 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_67_piece0 on b2edbf16b081:40551 in memory (size: 4.0 KiB, free: 433.6 MiB)\n24/03/26 16:18:13 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[259] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n24/03/26 16:18:13 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 78) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:13 INFO Executor: Running task 0.0 in stage 84.0 (TID 78)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_70_piece0 on b2edbf16b081:40551 in memory (size: 36.4 KiB, free: 433.7 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_69_piece0 on b2edbf16b081:40551 in memory (size: 2.8 KiB, free: 433.7 MiB)\n24/03/26 16:18:13 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_74_piece0 on b2edbf16b081:40551 in memory (size: 41.6 KiB, free: 433.7 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_84_piece0 on b2edbf16b081:40551 in memory (size: 45.5 KiB, free: 433.8 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_66_piece0 on b2edbf16b081:40551 in memory (size: 43.7 KiB, free: 433.8 MiB)\n24/03/26 16:18:13 INFO Executor: Finished task 0.0 in stage 84.0 (TID 78). 4086 bytes result sent to driver\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_73_piece0 on b2edbf16b081:40551 in memory (size: 39.8 KiB, free: 433.8 MiB)\n24/03/26 16:18:13 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 78) in 31 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n24/03/26 16:18:13 INFO DAGScheduler: ResultStage 84 (collectAsMap at RandomForest.scala:663) finished in 0.041 s\n24/03/26 16:18:13 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_78_piece0 on b2edbf16b081:40551 in memory (size: 43.2 KiB, free: 433.9 MiB)\n24/03/26 16:18:13 INFO DAGScheduler: Job 60 finished: collectAsMap at RandomForest.scala:663, took 0.144078 s\n24/03/26 16:18:13 INFO TorrentBroadcast: Destroying Broadcast(89) (from destroy at RandomForest.scala:674)\n24/03/26 16:18:13 INFO RandomForest: Internal timing for DecisionTree:\n24/03/26 16:18:13 INFO RandomForest:   init: 1.71341E-4\n  total: 0.973491577\n  findBestSplits: 0.964379623\n  chooseSplits: 0.947292537\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_89_piece0 on b2edbf16b081:40551 in memory (size: 360.0 B, free: 433.9 MiB)\n24/03/26 16:18:13 INFO MapPartitionsRDD: Removing RDD 244 from persistence list\n24/03/26 16:18:13 INFO BlockManager: Removing RDD 244\n24/03/26 16:18:13 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at RandomForest.scala:305)\n24/03/26 16:18:13 INFO BlockManagerInfo: Removed broadcast_76_piece0 on b2edbf16b081:40551 in memory (size: 1250.0 B, free: 433.9 MiB)\n24/03/26 16:18:13 INFO Instrumentation: [36166e1c] {\"numClasses\":3}\n24/03/26 16:18:13 INFO Instrumentation: [36166e1c] {\"numFeatures\":4}\n24/03/26 16:18:13 INFO CodeGenerator: Code generated in 25.892983 ms\n24/03/26 16:18:13 INFO Instrumentation: [36166e1c] training finished\n24/03/26 16:18:13 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61\n24/03/26 16:18:13 INFO DAGScheduler: Registering RDD 270 (map at MulticlassMetrics.scala:52) as input to shuffle 24\n24/03/26 16:18:13 INFO DAGScheduler: Got job 61 (collectAsMap at MulticlassMetrics.scala:61) with 1 output partitions\n24/03/26 16:18:13 INFO DAGScheduler: Final stage: ResultStage 86 (collectAsMap at MulticlassMetrics.scala:61)\n24/03/26 16:18:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)\n24/03/26 16:18:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 85)\n24/03/26 16:18:13 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[270] at map at MulticlassMetrics.scala:52), which has no missing parents\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 131.3 KiB, free 433.1 MiB)\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 51.9 KiB, free 433.1 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on b2edbf16b081:40551 (size: 51.9 KiB, free: 433.8 MiB)\n24/03/26 16:18:13 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[270] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n24/03/26 16:18:13 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 79) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:13 INFO Executor: Running task 0.0 in stage 85.0 (TID 79)\n24/03/26 16:18:13 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:13 INFO PythonRunner: Times: total = 284, boot = -1031, init = 1311, finish = 4\n24/03/26 16:18:13 INFO Executor: Finished task 0.0 in stage 85.0 (TID 79). 2510 bytes result sent to driver\n24/03/26 16:18:13 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 79) in 334 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n24/03/26 16:18:13 INFO DAGScheduler: ShuffleMapStage 85 (map at MulticlassMetrics.scala:52) finished in 0.352 s\n24/03/26 16:18:13 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:13 INFO DAGScheduler: running: Set()\n24/03/26 16:18:13 INFO DAGScheduler: waiting: Set(ResultStage 86)\n24/03/26 16:18:13 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:13 INFO DAGScheduler: Submitting ResultStage 86 (ShuffledRDD[271] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 4.7 KiB, free 433.1 MiB)\n24/03/26 16:18:13 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 433.1 MiB)\n24/03/26 16:18:13 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on b2edbf16b081:40551 (size: 2.8 KiB, free: 433.8 MiB)\n24/03/26 16:18:13 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (ShuffledRDD[271] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n24/03/26 16:18:13 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 80) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:13 INFO Executor: Running task 0.0 in stage 86.0 (TID 80)\n24/03/26 16:18:13 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:13 INFO Executor: Finished task 0.0 in stage 86.0 (TID 80). 2024 bytes result sent to driver\n24/03/26 16:18:13 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 80) in 8 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n24/03/26 16:18:13 INFO DAGScheduler: ResultStage 86 (collectAsMap at MulticlassMetrics.scala:61) finished in 0.015 s\n24/03/26 16:18:13 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n24/03/26 16:18:13 INFO DAGScheduler: Job 61 finished: collectAsMap at MulticlassMetrics.scala:61, took 0.372204 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This is a method we haven't seen yet,  a Naive Bayes Classifer","metadata":{}},{"cell_type":"code","source":"# -- Naive Bayes Classifier --\n\nnbc = NaiveBayes(smoothing=1.0,modelType=\"multinomial\", labelCol=\"label\",featuresCol=\"features_scaled\")    #instantiate the model\nnbc_model = nbc.fit(train_data)                                                                          #train the model\nnbc_pred = nbc_model.transform(test_data)                                                                #model predictions\n\n#Evaluate the Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nnbc_acc = evaluator.evaluate(nbc_pred)\n#print(\"Naive Bayes Accuracy =\", '{:.2%}'.format(nbc_acc))\nmodel_results.extend([[model[2],'{:.2%}'.format(nbc_acc)]])                                            #appending to list","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:18:26.752697Z","iopub.execute_input":"2024-03-26T16:18:26.753135Z","iopub.status.idle":"2024-03-26T16:18:28.093351Z","shell.execute_reply.started":"2024-03-26T16:18:26.753103Z","shell.execute_reply":"2024-03-26T16:18:28.092239Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"24/03/26 16:18:26 INFO Instrumentation: [dd919d40] Stage class: NaiveBayes\n24/03/26 16:18:26 INFO Instrumentation: [dd919d40] Stage uid: NaiveBayes_00f08a0a0bc3\n24/03/26 16:18:26 INFO Instrumentation: [dd919d40] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n24/03/26 16:18:26 INFO Instrumentation: [dd919d40] {\"labelCol\":\"label\",\"featuresCol\":\"features_scaled\",\"modelType\":\"multinomial\",\"smoothing\":1.0}\n24/03/26 16:18:26 INFO CodeGenerator: Code generated in 39.094439 ms\n24/03/26 16:18:27 INFO DAGScheduler: Registering RDD 278 (collect at NaiveBayes.scala:222) as input to shuffle 25\n24/03/26 16:18:27 INFO DAGScheduler: Got map stage job 62 (collect at NaiveBayes.scala:222) with 1 output partitions\n24/03/26 16:18:27 INFO DAGScheduler: Final stage: ShuffleMapStage 87 (collect at NaiveBayes.scala:222)\n24/03/26 16:18:27 INFO DAGScheduler: Parents of final stage: List()\n24/03/26 16:18:27 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:27 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[278] at collect at NaiveBayes.scala:222), which has no missing parents\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 98.0 KiB, free 433.0 MiB)\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 432.9 MiB)\n24/03/26 16:18:27 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on b2edbf16b081:40551 (size: 41.3 KiB, free: 433.8 MiB)\n24/03/26 16:18:27 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[278] at collect at NaiveBayes.scala:222) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n24/03/26 16:18:27 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 81) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:27 INFO Executor: Running task 0.0 in stage 87.0 (TID 81)\n24/03/26 16:18:27 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 45.587124 ms\n24/03/26 16:18:27 INFO PythonRunner: Times: total = 269, boot = -13151, init = 13416, finish = 4\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 5.628319 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 5.475784 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 6.750779 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 5.903248 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 6.375528 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 7.180369 ms\n24/03/26 16:18:27 INFO Executor: Finished task 0.0 in stage 87.0 (TID 81). 3315 bytes result sent to driver\n24/03/26 16:18:27 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 81) in 384 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n24/03/26 16:18:27 INFO DAGScheduler: ShuffleMapStage 87 (collect at NaiveBayes.scala:222) finished in 0.404 s\n24/03/26 16:18:27 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:27 INFO DAGScheduler: running: Set()\n24/03/26 16:18:27 INFO DAGScheduler: waiting: Set()\n24/03/26 16:18:27 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:27 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 7.368597 ms\n24/03/26 16:18:27 INFO SparkContext: Starting job: collect at NaiveBayes.scala:222\n24/03/26 16:18:27 INFO DAGScheduler: Got job 63 (collect at NaiveBayes.scala:222) with 1 output partitions\n24/03/26 16:18:27 INFO DAGScheduler: Final stage: ResultStage 89 (collect at NaiveBayes.scala:222)\n24/03/26 16:18:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n24/03/26 16:18:27 INFO DAGScheduler: Missing parents: List()\n24/03/26 16:18:27 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[282] at collect at NaiveBayes.scala:222), which has no missing parents\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 85.7 KiB, free 432.9 MiB)\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 37.7 KiB, free 432.8 MiB)\n24/03/26 16:18:27 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on b2edbf16b081:40551 (size: 37.7 KiB, free: 433.8 MiB)\n24/03/26 16:18:27 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[282] at collect at NaiveBayes.scala:222) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n24/03/26 16:18:27 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 82) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n24/03/26 16:18:27 INFO Executor: Running task 0.0 in stage 89.0 (TID 82)\n24/03/26 16:18:27 INFO ShuffleBlockFetcherIterator: Getting 1 (2.1 KiB) non-empty blocks including 1 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 4.529798 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 3.634475 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 3.807196 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 7.419769 ms\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 9.065384 ms\n24/03/26 16:18:27 INFO Executor: Finished task 0.0 in stage 89.0 (TID 82). 5625 bytes result sent to driver\n24/03/26 16:18:27 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 82) in 65 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n24/03/26 16:18:27 INFO DAGScheduler: ResultStage 89 (collect at NaiveBayes.scala:222) finished in 0.077 s\n24/03/26 16:18:27 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n24/03/26 16:18:27 INFO DAGScheduler: Job 63 finished: collect at NaiveBayes.scala:222, took 0.084087 s\n24/03/26 16:18:27 INFO CodeGenerator: Code generated in 8.172432 ms\n24/03/26 16:18:27 INFO Instrumentation: [dd919d40] {\"numFeatures\":4}\n24/03/26 16:18:27 INFO Instrumentation: [dd919d40] {\"numExamples\":139}\n24/03/26 16:18:27 INFO Instrumentation: [dd919d40] {\"numClasses\":3}\n24/03/26 16:18:27 INFO Instrumentation: [dd919d40] {\"sumOfWeights\":139.0}\n24/03/26 16:18:27 INFO Instrumentation: [dd919d40] training finished\n24/03/26 16:18:27 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61\n24/03/26 16:18:27 INFO DAGScheduler: Registering RDD 288 (map at MulticlassMetrics.scala:52) as input to shuffle 26\n24/03/26 16:18:27 INFO DAGScheduler: Got job 64 (collectAsMap at MulticlassMetrics.scala:61) with 1 output partitions\n24/03/26 16:18:27 INFO DAGScheduler: Final stage: ResultStage 91 (collectAsMap at MulticlassMetrics.scala:61)\n24/03/26 16:18:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n24/03/26 16:18:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)\n24/03/26 16:18:27 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[288] at map at MulticlassMetrics.scala:52), which has no missing parents\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 94.9 KiB, free 432.7 MiB)\n24/03/26 16:18:27 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 38.8 KiB, free 432.7 MiB)\n24/03/26 16:18:27 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on b2edbf16b081:40551 (size: 38.8 KiB, free: 433.7 MiB)\n24/03/26 16:18:27 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[288] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:27 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n24/03/26 16:18:27 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 83) (b2edbf16b081, executor driver, partition 0, PROCESS_LOCAL, 8201 bytes) \n24/03/26 16:18:27 INFO Executor: Running task 0.0 in stage 90.0 (TID 83)\n24/03/26 16:18:27 INFO BlockManager: Found block rdd_105_0 locally\n24/03/26 16:18:28 INFO PythonRunner: Times: total = 247, boot = -374, init = 617, finish = 4\n24/03/26 16:18:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n24/03/26 16:18:28 INFO Executor: Finished task 0.0 in stage 90.0 (TID 83). 2510 bytes result sent to driver\n24/03/26 16:18:28 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 83) in 319 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:28 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n24/03/26 16:18:28 INFO DAGScheduler: ShuffleMapStage 90 (map at MulticlassMetrics.scala:52) finished in 0.343 s\n24/03/26 16:18:28 INFO DAGScheduler: looking for newly runnable stages\n24/03/26 16:18:28 INFO DAGScheduler: running: Set()\n24/03/26 16:18:28 INFO DAGScheduler: waiting: Set(ResultStage 91)\n24/03/26 16:18:28 INFO DAGScheduler: failed: Set()\n24/03/26 16:18:28 INFO DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[289] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents\n24/03/26 16:18:28 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 4.7 KiB, free 432.7 MiB)\n24/03/26 16:18:28 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 432.7 MiB)\n24/03/26 16:18:28 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on b2edbf16b081:40551 (size: 2.8 KiB, free: 433.7 MiB)\n24/03/26 16:18:28 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1585\n24/03/26 16:18:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[289] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0))\n24/03/26 16:18:28 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n24/03/26 16:18:28 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 84) (b2edbf16b081, executor driver, partition 0, NODE_LOCAL, 7433 bytes) \n24/03/26 16:18:28 INFO Executor: Running task 0.0 in stage 91.0 (TID 84)\n24/03/26 16:18:28 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n24/03/26 16:18:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n24/03/26 16:18:28 INFO Executor: Finished task 0.0 in stage 91.0 (TID 84). 2024 bytes result sent to driver\n24/03/26 16:18:28 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 84) in 7 ms on b2edbf16b081 (executor driver) (1/1)\n24/03/26 16:18:28 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n24/03/26 16:18:28 INFO DAGScheduler: ResultStage 91 (collectAsMap at MulticlassMetrics.scala:61) finished in 0.012 s\n24/03/26 16:18:28 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n24/03/26 16:18:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n24/03/26 16:18:28 INFO DAGScheduler: Job 64 finished: collectAsMap at MulticlassMetrics.scala:61, took 0.360765 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There is an explicity \"garbage collection\" call to free memory that is not being used.   Python has automatic garbage collection,  but it is being used explictly here, this may be Spark-related, but I'm not sure right now\n\nJava is big on garbage collection and Spark runs in a Java environment","metadata":{}},{"cell_type":"code","source":"#freeing memory\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:18:34.403048Z","iopub.execute_input":"2024-03-26T16:18:34.403461Z","iopub.status.idle":"2024-03-26T16:18:34.551151Z","shell.execute_reply.started":"2024-03-26T16:18:34.403429Z","shell.execute_reply":"2024-03-26T16:18:34.549521Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"3743"},"metadata":{}}]},{"cell_type":"markdown","source":"Here is the output of the model results\n\ntabulate() looks handy, it looks like it was loaded from a package called (wait for it!) tabulate   ","metadata":{}},{"cell_type":"code","source":"print (tabulate(model_results, headers=[\"Classifier Models\", \"Accuracy\"]))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:18:41.787873Z","iopub.execute_input":"2024-03-26T16:18:41.788284Z","iopub.status.idle":"2024-03-26T16:18:41.796084Z","shell.execute_reply.started":"2024-03-26T16:18:41.788254Z","shell.execute_reply":"2024-03-26T16:18:41.794826Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Classifier Models    Accuracy\n-------------------  ----------\nDecision Tree        90.91%\nRandom Forest        100.00%\nNaive Bayes          100.00%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}